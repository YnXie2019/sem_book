[
["index.html", "Structural Equation Modeling in R for Ecology and Evolution 1 Preface", " Structural Equation Modeling in R for Ecology and Evolution Jonathan Lefcheck 2018-12-05 1 Preface Structural equation modeling is among the fastest growing statistical techniques in the natural sciences, thanks in large part to new advances and software packages that make it broadly applicable and easy to use. This book is meant to be an approachable guide to the theory, math, and application of SEM. It integrates code from popular open-source packages such as lavaan and piecewiseSEM. Each chapter ends with worked examples from the published literature. Moreover, as the author of the piecewiseSEM package, this format allows me to document newly-deployed functionality in the package, such as the addition of multigroup analysis and composite variables, new forms of standardization, and updates to model R2s. Happy reading! "],
["global-estimation.html", "2 Global Estimation 2.1 What is (Co)variance? 2.2 Regression Coefficients 2.3 Variance-based Structural Equation Modeling 2.4 Model Identifiability 2.5 Goodness-of-fit Measures 2.6 Model Fitting Using lavaan 2.7 References", " 2 Global Estimation 2.1 What is (Co)variance? The building block of the global estimation procedure for SEM is variance, specifically the covariance between variables. Before we delve into the specifics of this procedure, its worth reviewing the basics of variance and covariance. Variance is the degree of spread in a set of data. Formally, it captures the deviation of each point from the mean value across all points. Consider the variable \\(x\\). The variance of \\(x\\) is calculated as: \\[VAR_{x} = \\frac{\\sum(x_{i} - \\overline{x})^2}{n-1}\\] where \\(x_{i}\\) is each sample value, \\(\\overline{x}\\) is the sample mean, and \\(n\\) is the sample size. Similarly, for the response \\(y\\): \\[VAR_{y} = \\frac{\\sum(y_{i} - \\overline{y})^2}{n-1}\\] Note that, regardless of the actual values of the variables, variance are always positive (due to the squared term). The larger the variance, the more spread out the data are from the mean. Covariance is a measure of the dependency between two variables. Covariance can be formalized as: \\[COV_{xy} = \\frac{\\sum(x_{i} - \\overline{x}) (y_{i} - \\overline{y})}{n - 1}\\] If variation in \\(x\\) tends to track variation in \\(y\\), then the numerator is large and covariance is high. In this case, the two variables are then said to co-vary. Consider a simple example. In R, the function var computes variance, and cov the covariance. x &lt;- c(1, 2, 3, 4) y &lt;- c(2, 3, 4, 5) # variance in x sum((x - mean(x))^2)/(length(x) - 1) == var(x) ## [1] TRUE # variance in y sum((y - mean(y))^2)/(length(y) - 1) == var(y) ## [1] TRUE # covariance sum((x - mean(x)) * (y - mean(y)))/(length(x) - 1) == cov(x, y) ## [1] TRUE The variance and covariance depend on the magnitude of the units. If the units of \\(x\\) are much larger than \\(y\\), then the covariance will also be large: x &lt;- x * 1000 cov(x, y) ## [1] 1666.667 This property can make the interpretation and comparison of (co)variances potentially misleading if the units are very different between variables. To solve this issue, we can standardize the variables to have a mean of 0 and a variance of 1. This standardization is achieved by subtracting the mean from each observation, and dividing by the standard deviation (the square-root of the variance). This procedure is also known as the Z-transformation. zx &lt;- (x - mean(x)) / sd(x) zy &lt;- (y - mean(y)) / sd(y) # can also be obtained using the function `?scale` Replacing the values of x and y with the standardized versions in our calculation of covariance yields the Pearson product moment correlation, \\(r\\). Correlations are in units of standard deviations of the mean, and thus can be fairly compared regardless of the magnitude of the original variables. The function to compute the correlation is cor: sum(zx * zy)/(length(zx) - 1) == cor(x, y) ## [1] TRUE In our example, the two variables are prefectly correlated, so \\(r = 1\\). Incidentally, this is the same as dividing the covariance of \\(x\\) and \\(y\\) by the product of their standard deviations, which omits the need for the Z-transformation step but achieves the same outcome: (cov(x, y) / (sd(x) * sd(y))) == cor(x, y) ## [1] TRUE Now that we have reviewed these basic concepts, we can begin to consider them within the context of SEM. 2.2 Regression Coefficients The inferential heart of structural equation modeling are regression (or path) coefficients. These values mathematically quantify the linear dependence of one variable on another (or lack thereof). This verbage should sound familiar because that is what we have alreday established is the goal of covariance/correlation. In this section, we will demonstrate how path coefficients can be derived from correlation coefficients and explore the 8 “rules of path coefficients.” First, we must define the important distinction between a regression (path) coefficient and a correlation coefficient. In a simple linear regression, one variable \\(y\\) is the response and another \\(x\\) is the predictor. The association between the two variables is used to generator the predictor \\(\\hat{y}\\): \\[\\hat{y} = bx + a\\] where \\(b\\) is the regression coefficient and \\(a\\) is the intercept. Its important to note that \\(b\\) implies a linear relationship, i.e., the relatoinship between \\(x\\) and \\(y\\) can be captured by a straight line. The regression coefficient between \\(x\\) and \\(y\\) can be related to the correlation coefficient through the following equation: \\[b_{xy} = r_{xy} (SD_{y}/SD_{x})\\] If the variables have been Z-transformed, then the \\(SD_{x} = SD_{y} = 1\\) and \\(b_{xy} = r_{xy}\\). This brings us to our first key point: when the variables have been scaled to mean = 0 and variance = 1, then the regression coefficient is the correlation coefficient. For multiple regression, they are the partial correlation coefficients. We refer to these as standardized coefficients. Unstandardized coefficients, then, are reported in their raw units. As with variance, then, their values depend on the unit of measure. In fact, the unstandardized coefficient can be related to the variance through the following equation: \\[b_{xy} = \\frac{COV_{xy}}{VAR_{x}}\\] In mathematical terms, then, the unstandardized coefficients are scaled by the variance of the predictor, while the standardized variance by the cross-product of the standard deviations of both \\(x\\) and \\(y\\). We can demonstrate these principles using a simple example: set.seed(111) data &lt;- data.frame(y1 = runif(100)) data$x1 &lt;- data$y1 + runif(100) unstd.model &lt;- lm(y1 ~ x1, data) # get unstandardized coefficient summary(unstd.model)$coefficients[2, 1] ## [1] 0.462616 # now using covariance (cov(data$y1, data$x1) / var(data$x)) ## [1] 0.462616 # repeat with scaled data std.model &lt;- lm(y1 ~ x1, as.data.frame(apply(data, 2, scale))) # get standardized coefficient summary(std.model)$coefficients[2, 1] ## [1] 0.6964617 # now using correlation cor(data$y1, data$x1) ## [1] 0.6964617 The concepts of variance, covariance, and correlation therefore directly inform the calculation of unstandardized and standardized regression coefficients, and lend them their unique properties that we will now cover as the 8 “rules of path coefficients.” 2.2.1 Rule 1: Unspecified relationships among exogenous variables are simply their bivariate correlations. Variables that only have paths emanating from them (i.e., do not have arrows going into them) are called exogenous variables. If there is not a directed path between two exogenous variables, then their relationship can be expressed by a the simple correlation between them. This is sometimes, but not necessarily, indicated by a double-headed arrow. So \\(x1 &lt;-&gt; x2 == cor(x1, x2)\\). 2.2.2 Rule 2: When two variables are connected by a single path, the coefficient of that path is the regression coefficient. For this rule, we will expand upon our earlier example to construct a simple path diagram: sem_model1 data$y2 &lt;- data$y1 + runif(100) In this case, the path coefficient connecting \\(x1 -&gt; y1\\) is the regression coefficient of \\(y ~ x\\). Similarly, the path coefficient connecting \\(y1 -&gt; y2\\) is the regression coefficient of \\(y2 ~ y1\\). If the data are standardized, then the regression coefficient is the correlation coefficient. (pathx1_y1 &lt;- summary(lm(y1 ~ x1, as.data.frame(apply(data, 2, scale))))$coefficients[2, 1]) ## [1] 0.6964617 cor(data$y1, data$x1) ## [1] 0.6964617 (pathy1_y2 &lt;- summary(lm(y2 ~ y1, as.data.frame(apply(data, 2, scale))))$coefficients[2, 1]) ## [1] 0.6575341 cor(data$y2, data$y1) ## [1] 0.6575341 2.2.3 Rule 3: The strength of a compound path (one that includes multiple links) is the product of the individual coefficients. One of the strengths of SEM is being able to quantify indirect or cascading linkages. This is accomplished by simply multiplying the path coefficients. So the effect of \\(x1\\) on \\(y2\\) is the product of the coefficient of the path \\(x1 -&gt; y1\\) and \\(y1 -&gt; y2\\): pathx1_y1 * pathy1_y2 ## [1] 0.4579473 By our earlier logic, this value should equal the correlation between \\(x1\\) and \\(y2\\): cor(data$y2, data$x1) ## [1] 0.4484743 But wait! The correlations are not the same. This result implies that the relationship between \\(x1\\) and \\(y2\\) cannot be fully explained by the indirect path through \\(y1\\). Rather, we require additional information to solve this problem, and it comes in the form of the missing link between \\(x1 -&gt; y2\\), which we can add to the model: sem_model2 Introducing this path raises a new issue: the relationship between \\(y1\\) and \\(y2\\) now arises from two sources. The first is their direct link, the second is from the indirect effect of \\(x1\\) through \\(y1\\). We require a new approach to be able to compute the independent effects of each variable on the others, which comes in the form of the ‘partial’ regression coefficient. 2.2.4 Rule 4. When variables are connected by more than one pathway, each pathway is the ‘partial’ regression coefficient. A partial regression coefficient accounts for the joint influence of more than one variable on the response. In other words, the coefficient for one predictor controls for the influence of other predictors in the model. In this new model, \\(y2\\) is affected by two variables: \\(x1\\) and \\(y1\\). Procedurally, this involve removing the shared variance between \\(x1\\) and \\(y1\\) so that their effects can be independently derived. We can calculate this relationship through the following equation: \\[b_{y2x1} = \\frac{r_{x1y2} - (r_{x1y1} \\times r_{y1y2})}{1 - r_{x1y1}^2}\\] which removes the joint influence of \\(y1\\) and \\(x1\\) on \\(y2\\), and scales this effect by the shared variance between \\(x1\\) and \\(y1\\). The result is the partial effect of \\(x1\\) on \\(y2\\). (partialx1 &lt;- (cor(data$x1, data$y2) - (cor(data$x1, data$y1) * cor(data$y1, data$y2))) / (1 - cor(data$x1, data$y1)^2)) ## [1] -0.0183964 It is important to note that partial coefficients implement a statistical (rather than experimental) control. In other words, the partial effect of \\(x1\\) controls for the contributions of \\(y1\\). Thus, partial effects are useful in implementing statistical controls in situations where experimental controls are impossible. Similarly, the partial effect of \\(y1\\) on \\(y2\\) is given by: \\[b_{y2y1} = \\frac{r_{y2y1} - (r_{y2x1} \\times r_{y1x1})}{1 - r_{x1y1}^2}\\] (partialy1 &lt;- (cor(data$y2, data$y1) - (cor(data$y2, data$x1) * cor(data$y1, data$x1))) / (1 - cor(data$x1, data$y1)^2)) ## [1] 0.6703465 We can arrive at the same answer by looking at the (standardized) coefficients obtained through a multiple regression: summary(lm(y2 ~ x1 + y1, as.data.frame(apply(data, 2, scale))))$coefficients[2:3, 1] ## x1 y1 ## -0.0183964 0.6703465 partialx1; partialy1 ## [1] -0.0183964 ## [1] 0.6703465 Another way of looking at this is by removing the variance \\(x1\\) explained by \\(y1\\), then regressing those values against \\(y2\\). In other words, we can extract the residuals (i.e., unexplained variance) in \\(x1\\) by \\(y1\\) and use those to predict \\(x2\\). residsx1 &lt;- residuals(lm(x1 ~ y1, as.data.frame(apply(data, 2, scale)))) summary(lm(scale(data$y2) ~ residsx1))$coefficients[2, 1] ## [1] -0.0183964 partialx1 ## [1] -0.0183964 Indeed, this procedure gives us the same value as the former equation or the multiple regression. However, this raises the interesting notion of residual error. The second equation still has variance \\(y2\\) that is unexplained by the residuals of \\(x1\\). In other words, the model does not perfectly predict \\(y2\\). The idea of residual (unexplained) variance leads us the fifth rule of path coefficients. 2.2.5 Rule 5: Errors on endogenous variables relate the unexplained correlations or variances arising from unmeasured variables. Variables that have paths entering them (regardless of whether they also have paths emanating from them) are called endogenous variables. In this example, \\(y1\\) and \\(y2\\) are both endogenous variables, even though \\(y\\) goes onto also predict \\(y2\\), because both have arrows entering them. If the variance explained by the model is captured by the \\(R^2\\) statistics, then the unexplained or residual variance is \\(1 - R^2\\). For example, the error variance on \\(y2\\) is: 1 - summary(lm(y2 ~ y1 + x1, as.data.frame(apply(data, 2, scale))))$r.squared ## [1] 0.5674746 These values capture the other (unknown) sources that cause the correlation between \\(y2\\) and the other variables to deviate from 1. In other words, if we measured all the influences on \\(y2\\) then the prediction error would be 0 because we would have explained everything that affects variance in \\(y2\\). This idea is nicely illustrated with the relationship between \\(x1\\) and \\(y1\\), where the square-root of variance explained is simply the correlation coefficient: sqrt(summary(lm(y1 ~ x1, as.data.frame(apply(data, 2, scale))))$r.squared) ## [1] 0.6964617 cor(data$y1, data$x1) ## [1] 0.6964617 (This is true because there are no other predictors of \\(y1\\).) Thus, 1 - this value is the unexplained correlation between the two arising from other sources. In a path diagram, error variances are often represented as \\(\\zeta\\) with an arrow leading into the endogenous variable. The path coefficient is the unexplained variance, but is often expressed as the error correlation: \\(\\sqrt(1 - R^2)\\), in keeping with the presentation of the other (standardized) coefficients. 2.2.6 Rule 6: Unanalyzed (residual) correlations among two endogenous variables are their partial correlations. Imagine we remove the path from \\(y1 -&gt; y2\\): sem_model3 Both variables are endogenous and their relationship can still be quantified, just not in a directed way. If they were exogenous variables, the relationship would be their bivariate correlation (Rule #1), but in this case, we have to remove the effects of \\(x1\\) on both variables. \\[r_{y1y2\\bullet x1} = \\frac{r_{y1y2} - (r_{x1y1} \\times r_{x1y2})}{\\sqrt((1 - r_{x1y1}^2)(1 - r_{x1y2}^2))}\\] This equation removes the effect \\(x1\\) and scales by the shared variance between \\(x1\\) and both endogenous variables. (errory1y2 &lt;- (cor(data$y1, data$y2) - (cor(data$x1, data$y1) * cor(data$x1, data$y2))) / sqrt((1 - cor(data$x1, data$y1)^2) * (1 - cor(data$x1, data$y2)^2))) ## [1] 0.5381952 This is the same as the correlation between the residuals of the two models: (cor( resid(lm(y1 ~ x1, as.data.frame(apply(data, 2, scale)))), resid(lm(y2 ~ x1, as.data.frame(apply(data, 2, scale)))) )) ## [1] 0.5381952 errory1y2 ## [1] 0.5381952 Hence these are known as correlated errors and are represented by double-headed arrows between the errors of two endogenous variables. (Often the errors are omitted, and the graph simply depicts a double-headed arrow between the variables themselves, but the correlation is truly among their errors.) If the presence of \\(x1\\) explains all of the variation in \\(y1\\) and \\(y2\\), then their partial correlation will be 0. In this case, the two endogenous variables are said to be conditionally independent, or that they are unrelated conditional on the joint influence of \\(x1\\). If the two are conditionally independent, then the correlation between \\(y1\\) and \\(y2\\) is the product of the correlations between \\(y1\\) and \\(x1\\), and \\(y2\\) and \\(x1\\). \\[r_{y1y2} = r_{y1x1} \\times r_{y2x1}\\] (If we replace this term in the previous equation, the numerator becomes 0 and so does the partial correlation.) Let’s calculate this value: cor(data$y1, data$x1) * cor(data$y2, data$x1) ## [1] 0.3123451 Ah, the two are very different, implying that \\(y1\\) and \\(y2\\) are not conditionally independent given the joint influence of \\(x1\\). In other words, there are other, unmeasured sources of variance that are influencing the relationship between these two variables. The concept of conditional independence is critical in the implementation of local estimation, principally in the tests of directed separation that form the basis of the goodness-of-fit statistic, which we will revisit later. Now that we have derived all the quantities related to direct, indirect, and error variances/correlations, we have all the information necessary to calculate total effects. 2.2.7 Rule 7: The total effect one variable has another is the sum of its direct and indirect effects. If we return to out previous path model, which reinstates the path between \\(y1 -&gt; y2\\), the total effect of \\(x1\\) on \\(y2\\) includes the direct effect, as well as the indirect effect mediated by \\(y1\\). (totalx1 &lt;- partialx1 + cor(data$y1, data$x1) * partialy1) ## [1] 0.4484743 This value can be used to demonstrate the final rule. 2.2.8 Rule 8: The total effect (including undirected paths) is equivalent to the total correlation. We can test this rule easily: totalx1 == cor(data$y2, data$x1) ## [1] TRUE Indeed, the total effect equals the correlation! If we consider the path model without the directed link between \\(y1\\) and \\(y2\\), the correlation between \\(y1\\) and \\(y2\\) considers the total effect and undirected effects (i.e., correlated errors): (totaly1y2 &lt;- cor(data$y1, data$x1) * cor(data$y2, data$x1) + errory1y2 * sqrt(1 - summary(lm(y1 ~ x1, data))$r.squared) * sqrt(1 - summary(lm(y2 ~ x1, data))$r.squared)) ## [1] 0.6575341 totaly1y2 == cor(data$y1, data$y2) ## [1] TRUE This example closes our discussion of path coefficients. The major points to remember are: standardized coefficients reflect (partial) correlations the indirect effect of one variable on another is obtained by multiplying the individual path coefficients (standardized or unstandardized) the total effect is the sum of direct and indirect paths the bivariate correlation is the sum of the the total effect plus any undirected paths An understanding of covariances and correlations is essential to understanding the solutions provided by a global estimation approach to SEM. 2.3 Variance-based Structural Equation Modeling The classical approach to SEM is based on the the idea of variance and covariances. With &gt;2 variables, you can construct a variance-covariance matrix, where the diagonals are the variances of each variable and the off-diagonals are the covariances between each pair. Consider our last example: cov(data) ## y1 x1 y2 ## y1 0.07602083 0.07970883 0.07178090 ## x1 0.07970883 0.17230020 0.07370632 ## y2 0.07178090 0.07370632 0.15676481 returns the variance-covariance matrix for the three variables \\(x1\\), \\(y1\\), and \\(y2\\). We would call this the observed global variance-covariance matrix. The entire machinary behind covariance-based SEM is to reproduce that global variance-covariance matrix. In fact, all of covariance-based SEM can be boiled down into a simple equation: \\[\\Sigma = \\Sigma(\\Phi)\\] where \\(\\Sigma\\) is the observed variance-covariance matrix, and \\(\\Sigma(\\Phi)\\) is the model-estimated covariance matrix expressed in terms of \\(\\Phi\\), the matrix of model-estimated parameters (i.e., coefficients). In other words, this equation shows that the observed covariances can be understood in terms of statistical parameters that can be used to predict these same covariances. We have already shown that linear regression can be expressed in terms of these same principles, and so it follows that covariance-based SEM is simply a multivariate approach to regression. The question is: how do we arrive at \\(\\Sigma(\\Phi)\\), or more relevantly, how do we estimate the matrix of model parameters \\(\\Phi\\) that lead to the estimated variance-covariance matrix? The most common tool is maximum-likelihood estimation, which iteratively searches parameter space and continually refines estimates of parameter values such that the differences between the observed and expected variance-covariance matrices. The maximum-likelihood fitting function can be expressed as: \\[F_{ML} = log|\\hat{\\Sigma}| + tr(S\\hat{\\Sigma}^{-1}) - log|S| - (p + q)\\] where \\(\\Sigma\\) is the modeled covariance matrix, \\(S\\) is the observed covariance matrix, \\(p\\) is the number of endogenous variables, and \\(q\\) is the number of exogenous variables. \\(tr\\) is the trace of the matrix (sum of the diagonal) and the \\(^{-1}\\) is the inverse of the matrix. Maximum-likelihood estimators have a few desireable properties, principally that they provide unbiased estimates with a sufficiently large sample size and they are invariant to the scales of the variables. A number of assumptions accompany maximum-likelihood fitting: - variables must exhibit multivariate normality. Oftentimes this is the not case: dummy variables, interactions and other product terms have non-normal distrbutions. However, \\(F_{ML}\\) is fairly robust to violations of multinormality, especially as the sample size grows large. - the observed matrix \\(S\\) must be positive-definite. This means there are no negative variances, an implied correlation &gt; 1.0, or redundant variables (one row is a linear function of another). - finally, \\(F_{ML}\\) assumes sufficiently large sample size. The notion of sample size is a good one: as models become increasingly complex, they require more data to fit. The issue of model ‘identifiability’ and sample size is dealt with in the next section. 2.4 Model Identifiability Like any statistical technique, having sufficient power to test your hypotheses is key to arriving at robust unbiased inferences about your data. This requirement is particularly relevant to SEM, which often evaluates multiple hypotheses simultaneously, and therefore requires more data than other approaches. In this section, we will briefly review the idea of model ‘identifiability’ and sample size requirements. A model is ‘identified’ if we can uniquely estimate each of its parameters. This not includes in the matrix of parameter estimates, but also their errors. In other words, we need at least as many ‘known’ pieces of information as ‘unknowns’ at minimum to be able to fit a model. Consider the following equation: \\[a + b = 8\\] We have 1 piece of known information, \\(8\\), and two unknowns, \\(a\\) and \\(b\\). There are a number of solutions for \\(a\\) and \\(b\\) (e.g., 1 and 7, 2 and 6, etc), and thus the equation is not solvable. In this case, the model would be underidentified because we lack sufficient information to arrive at a unique solution. Now consider another equation, in addition to the first: \\[a = 3b\\] With this equation, we now have enough information to uniquely solve for \\(a\\) and \\(b\\): \\[(2b) + b = 8\\] \\[ 4b = 8\\] \\[b = 8 / 4 = 2\\] \\[a + 2 = 8\\] \\[a = 8 - 2 = 6\\] Thus we have arrived at a single solution for \\(a\\) and \\(b\\). We call this system of equations just identified since we have just enough information to solve for the unknowns. Finally, consider a third equation: \\[2a - 4 = 4b\\] We now have more pieces of known information than unknowns, since we have already arrived at a solution for both \\(a\\) and \\(b\\) based on the previous two equations. In this case, we call the system of the equations overidentified because we have more information than is necessary to arrive at unique solutions for our unknown variables. This is the desireable state, because that extra information can be used, for example, to derive additional estimates of model fit. You may alternately hear models referred to as saturated. Such a model would be just identified; an unsaturated model would be overidentified and and an oversaturated model would be underidentified. There is a handy rule that can be used to quickly gauge whether a model is under-, just, or overidentified: the “t-rule.” The t-rule takes the following form: \\[t \\leq \\frac{n(n+1)}{2}\\] where \\(t\\) is the number of unknowns (parameters to be estimated) and \\(n\\) is the number of knowns (observed variables). The left hand side is how many pieces of information we want to know. The right hand side reflects the information we have to work with, and is equal to the number of unique cells in the observed variance-covariance matrix (diagonal = variance, and lower triangle = covariances). Consider the simple mediation model from earlier: sem_model1 In this model, we have several pieces of known information: \\(x1\\), \\(y1\\), and \\(y2\\). So \\(n = 3\\) for this model. We need to estimate the parameters related each set of relationships (\\(b_{x1y1}\\) and \\(b_{y1y2}\\)). These amount to the two covariances, but recall from the first section we also need the variances to derive those estimates (\\(var_{x1}\\), \\(var_{y1}\\), \\(var_{y2}\\)). So the total number of unknowns is \\(t = 5\\). We can plug in these values to see if we meet the t-rule: \\[5 \\leq \\frac{3(3+1)}{2} = 6\\] In this case \\(5 \\leq 6\\) holds true and we have enough information to arrive at a unique solution. Note that the right hand side of the equation is the number of entries in the variance-covariance matrix: 3 variances (diagonal) plus 3 covariances (off-diagonal). Let’s consider our second model, which adds another path: sem_model2 Now we must additionally estimate the path from \\(x1\\) to \\(y2\\) so our value of \\(t = 5 + 1\\). However, \\(6 \\leq 6\\) and so the t-rule is still satisfied. Identifying the number of parameters can sometimes be tricky because path diagrams are not always drawn with error variances on the endogenous variables. Additionally, multiple exogenous variables also have a covariance that must be estimated: this is depicted as a non-directional or double-headed error between every pair of exogenous variables. However, these double-headed arrows are rarely drawn, even though they exist. Thus it can be tricky to identify \\(n\\) in the above equation. In such cases, it is equally valid to simply count the number of unique cells in the variance-covariance matrix (the diagonal and the lower off-diagonal). If we were to consider a more complex model, such as one with a feedback from \\(y2\\) to \\(y1\\) (in addition to the path from \\(y1 -&gt; y2\\)) then we would not have enough information to solve the model, which would be underidentified. Models with bi-directional feedbacks (with separate arrows going in each direction, as opposed to a single double-headed arrow) are referred to as non-recursive. These feedbacks can also occur among variables, for instance: \\(x1 -&gt; y1 -&gt; y2 -&gt; x1\\) would also be a non-recursive model. Recursive models, then, lack such feedbacks. Identifiability of non-recursive is tricky. Such models must satisfy the order condition. This condition tests whether variables involved in the feedback have unique information. In our above example of \\(y2\\) also affecting \\(y1\\), \\(y1\\) has unique information in the form of \\(x1\\) but \\(y2\\) has no unique information, so it fails the order condition. The order condition can be evaluated using the following equation: \\[G \\leq H\\] where \\(G\\) = the number of incoming paths, and \\(H\\) = the number of exogenous variables + the number of indirectly-connected endogenous variabls. In the previous example, \\(G = 2\\) while \\(H = 1\\), so the model fails the order condition, as noted. Model identification is only the first step in determining whether a model can provide unique solutions: sample size can also restrict model fitting by not providing enough replication for the ML-fitting function to arrive at a stable set of estimates for the path coefficients. The basic rule-of-thumb is that the level of replication should be at least 5 times the number of estimated coefficients (not error variances or other correlations). So in our previous path model, we are estimating two relationships, so we require at least \\(n = 10\\) to fit that model. However, this value is a lower limit: ideally, replication is 5-20x the number of estimated parameters. The larger the sample size, the more precise (unbiased) the estimates will be. Identifiability and replication are key in not only providing an actual solution, but also in providing extra information with which to evaluate model fit, the topic of the next section. 2.5 Goodness-of-fit Measures As we have established, the purpose of covariance-based SEM is to reproduce the global observed variance-covariance matrix. However, given that our hypothesized relationships may not actually match the data, we must be prepared to evaluate how well the model-estimated variance-covariance matrix matches the observed variance-covariance matrix. Recall that in the section on Path Coefficients, we evaluated the error variance/correlation as reflecting outside sources of variation uncaptured by our measured variables. High error variances would lead to less accurate estimates of the relationships among variables, and thus a high level of disagreement among the observed and model-implied variance-covariance matrix. Also recall our formula for the maximum-likelihood fitting function: \\[F_{ML} = log|\\hat{\\Sigma}| + tr(S\\hat{\\Sigma}^{-1}) - log|S| - (p + q)\\] where \\(\\Sigma\\) is the modeled covariance matrix, \\(S\\) is the observed covariance matrix, \\(p\\) is the number of endogenous variables, and \\(q\\) is the number of exogenous variables. \\(tr\\) is the trace of the matrix (sum of the diagonal) and the \\(^{-1}\\) is the inverse of the matrix. In the event that \\(\\Sigma = S\\), then the first two terms would equal 0, and similarly for the second two terms. Thus a model where \\(F_{ML} = 0\\) implies perfect fit because the observed covariance matrix has been exactly reproduced. Oppositely, a large value of \\(F_{ML}\\) would imply increasing discrepancy between the observed and model-implied variance-covariance matrices. This could be interpreted as a ‘poor fit’ for the model. In fact, \\(F_{ML}\\) is \\(\\chi^2\\)-distributed such that: \\[\\chi^2 = (n - 1)F_{ML}\\] which allows us to actually quantify model fit. We can then formally compare the \\(\\chi^2\\) statistic to the \\(\\chi^2\\)-distribution with \\(n - 1\\) degrees of freedom. Failing to reject the null hypothesis that the \\(\\chi^2\\) statistic is different from 0 (perfect fit) implies a generally good representation of the data (P &gt; 0.05). Alternately, rejecting the null implies that the \\(\\chi^2\\) statistic is large, as is the discrepancy between the observed and modeled variance-covariance matrices, thus implying a poor fit to the data (P &lt; 0.05). Interpreting the outcome of the significance test is often tricky, as a significant P-value indicates poor fit, so be careful. The \\(\\chi^2\\) index also provides a way to gauge the relative fit of two models, one of which is nested within the other. The \\(\\chi^2\\) difference test is simply the difference in \\(\\chi^2\\) values between the two models, with the degrees of freedom being the difference in the degrees of freedom between the two models. The resulting statistic can then be compared to a \\(\\chi^2\\) table to yield a significance value. Again, this test is for nested models. For non-nested models, other statistics allow for model comparisons, including AIC and BIC. An AIC or BIC score $$2 is generally considered to indicate significant differneces among models, with smaller values indicating equivalency between the two models. \\(\\chi^2\\) tests tend to be affected by sample size, with larger samples more likely to generate poor fit due to small absolute deviations. As a reuslt, there are several other fit indices for covariance-based SEM that attempt to correct for this problem: Root-mean squared error of approximation (RMSEA): this statistic penalizes models based on sample size. An acceptable value is generally &lt;0.10 and a good value is anything &lt;0.8. Comparative fit index (CFI): this statistic considers the deviation from a ‘null’ model. In most cases, the null estimates all variances but sets the covariances to 0. A value &gt;0.9 is considered good. Standardized root-mean squared residual (SRMR): the standardized difference between the observed and predicted correlations. A value &lt;0.08 is considered good. There are a number of other fit statistics that have been developed which you may run across. This website has a fairly comprehensive overview. What happens if the model doesn’t fit? Depending on the goals of your analysis (e.g., exploratory) you may wish to see which parts of your model have failed to be reproduced by the model-implied variance-covariance matrix. This can be achieved in two ways: examination correlation of model residuals: parameters with large residual correlations (difference between observed and expected) could suggest missing information or linkages. modification indices, or the expected decrease in the \\(\\chi^2\\) if a missing path were to be included in the model. A high value of a modification index would suggest the missing path should be included. (Tests of directed separation, which we cover in the chapter on Local Estimation, provide similar insight and are returned automatically by piecewiseSEM.) Users should take caution when exploring these techniques as to avoid dredging the model. SEM is a technique that relies heavily on informed model specification: adding paths in that are suggested by the data but not anticipated by the user to achieve adequate fit, or comparing all sub-models using AIC, for example, might be appropriate in other applications, but ignore the basic philosophy behind SEM. 2.6 Model Fitting Using lavaan We now have all the pieces necessary to fit an SEM using a covariance-based approach. The package to do so is called lavaan: library(lavaan) ## This is lavaan 0.6-2 ## lavaan is BETA software! Please report any bugs. To demonstrate the functionality of this package, let’s use the data from Grace &amp; Keeley (2006), which is included in the piecewiseSEM package: library(piecewiseSEM) ## ## This is piecewiseSEM version 2.1.0 ## ## ## If you have used the package before, it is strongly recommended you read Section 3 of the vignette(&#39;piecewiseSEM&#39;) to familiarize yourself with the new syntax ## ## Questions or bugs can be addressed to &lt;LefcheckJ@si.edu&gt; data(keeley) In their study, Grace &amp; Keeley wanted to understand patterns in plant diversity following disturbance, in this case wildfires in California. 2.6.1 lavaan vs lm For purposes of exploration, let’s first consider the relationship between fire severity and stand age (with older stands having more combustible materials) keeley sem This is both a linear regression but also a simple SEM, and thus both can be fit using packages in R. The package to fit the SEM using covariance-based methods is called lavaan (for LAtent VAriable ANalysis, which we will get to in another chapter). In lavaan, the syntax is the same as in other modeling functions in R with one key distinction: formulae are passed as character strings. To fit a model in lavaan, its first necessary to break down the component models by the endogenous (response) variables and code them as characters. For example: keeley_formula1 &lt;- &#39;firesev ~ age&#39; class(keeley_formula1) ## [1] &quot;character&quot; The function used to fit the model is called (unsurprisingly) sem and accepts the formula string and the dataset: keeley_sem1 &lt;- sem(keeley_formula1, data = keeley) As with any other model, the function to retrieve the output is summary: summary(keeley_sem1) ## lavaan 0.6-2 ended normally after 11 iterations ## ## Optimization method NLMINB ## Number of free parameters 2 ## ## Number of observations 90 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 0 ## Minimum Function Value 0.0000000000000 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## firesev ~ ## age 0.060 0.012 4.832 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .firesev 2.144 0.320 6.708 0.000 The output is organized into a few sections. First is the likelihood optimization method, number of parameters, the total sample size for the model, the estimator (\\(F_{ML}\\) is the default) and the fit statistic. The model has \\(\\chi^2 = 0\\) with 0 degrees of freedom: this is because we have as many knowns as unknowns, and thus the model is just identified or saturated. To show this, we can apply the t-rule: we must estimate the two variances of the variables plus their path coefficient (\\(t = 3\\)) and know the values of the two variables (\\(n = 2\\)). Recall the equation for the t-rule \\(t \\leq n(n + 1)/2\\), so \\(3 = 2(2+1)/2 = 6/2 = 3\\), and therefore the model is saturated. Next up are the actual parameter estimates: the relationship between fire severity and stand age is \\(\\beta = 0.06\\) with \\(P &lt; 0.001\\). The model has reports the estimated error variance on the endogenous variable. We can dissect this output a little more. First, let’s fit the corresponding linear model using lm: keeley_mod &lt;- lm(firesev ~ age, data = keeley) summary(keeley_mod)$coefficients ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 3.03920623 0.35543253 8.550726 3.448774e-13 ## age 0.05967903 0.01249008 4.778113 7.027847e-06 You’ll notice that we get the same effect of age on fire severity \\(\\beta = 0.0596\\), but we also get an intercept, which is missing from the previous input. We can force lavaan to return the intercept using the argument meanstructure = T to the sem function: summary(sem(keeley_formula1, keeley, meanstructure = T)) ## lavaan 0.6-2 ended normally after 14 iterations ## ## Optimization method NLMINB ## Number of free parameters 3 ## ## Number of observations 90 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 0 ## Minimum Function Value 0.0000000000000 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## firesev ~ ## age 0.060 0.012 4.832 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .firesev 3.039 0.351 8.647 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .firesev 2.144 0.320 6.708 0.000 which now returns the estimate of the intercept for fire severity. This value is the same as returned by lm. Returning to our exploration of how path coefficients are calculated, the slope of a simple linear regression is \\(b_{xy} = COV_{xy}/VAR_{x}\\), which we can recover from the raw data: cov(keeley[, c(&quot;firesev&quot;, &quot;age&quot;)])[2, 1]/var(keeley$age) ## [1] 0.05967903 Note that this value is the same returned from both sem and lm. Recall also for simple linear regression that the standardized coefficient (mean = 0 and variance = 1) is equal to the correlation: cor(keeley$firesev, keeley$age) ## [1] 0.4538654 We can obtain the standardized coefficient from lm using the coefs function from piecewiseSEM: coefs(keeley_mod) ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## 1 firesev age 0.0597 0.0125 88 4.7781 0 0.4539 ## ## 1 *** and indeed, it equals the bivariate correlation! To return the standardized coefficients using lavaan requires a separate function or another argument. The function is standardizedsolution and returns a table of the standardized coefficients: standardizedsolution(keeley_sem1) ## lhs op rhs est.std se z pvalue ci.lower ci.upper ## 1 firesev ~ age 0.454 0.079 5.726 0 0.299 0.609 ## 2 firesev ~~ firesev 0.794 0.072 11.035 0 0.653 0.935 ## 3 age ~~ age 1.000 0.000 NA NA 1.000 1.000 This output does not return the raw coefficients, however, or any other information about the model that is useful in interpretation. The obtain a single output, you can pass the argument standardize = T to summary: summary(keeley_sem1, standardize = T) ## lavaan 0.6-2 ended normally after 11 iterations ## ## Optimization method NLMINB ## Number of free parameters 2 ## ## Number of observations 90 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 0 ## Minimum Function Value 0.0000000000000 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## firesev ~ ## age 0.060 0.012 4.832 0.000 0.060 0.454 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .firesev 2.144 0.320 6.708 0.000 2.144 0.794 Now, a few columns are added at the end to report the standardized coefficients. standardizedsolution also returned the error variance on fire severity, which is \\(1 - R^2\\). However, lavaan also doesn’t return the \\(R^2\\) value by default, but can be retrieved using the argument rsq = T for summary: summary(keeley_sem1, standardize = T, rsq = T) ## lavaan 0.6-2 ended normally after 11 iterations ## ## Optimization method NLMINB ## Number of free parameters 2 ## ## Number of observations 90 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 0 ## Minimum Function Value 0.0000000000000 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## firesev ~ ## age 0.060 0.012 4.832 0.000 0.060 0.454 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .firesev 2.144 0.320 6.708 0.000 2.144 0.794 ## ## R-Square: ## Estimate ## firesev 0.206 You’ll note that, per Rule 5 of path coefficients, the error variance is \\(1 - R^2\\). 2.6.2 SEM using lavaan Now that we have covered the basics of lavaan, let’s fit a slightly more complicated SEM. This model is a simplified subset of the full model presented by Grace &amp; Keeley: keeley sem Here, we test the hypotheses that total cover of plants is a function of the severity of the burn, which in turn is informed by how old the plants are in a particular plot (which we have already investigated). This test is known as full mediation, in other words that the effect of age is fully mediated by fire severity (we will test another scenario shortly). Again, we must provide the formulae as a character string. This model can be broken down into two equation representing the two endogenous variables: keeley_formula2 &lt;- &#39; firesev ~ age cover ~ firesev &#39; Multiple equations will go on separate lines so that lavaan can properly parse the model. Now let’s fit the SEM and examine the output: keeley_sem2 &lt;- sem(keeley_formula2, data = keeley) summary(keeley_sem2, standardize = T, rsq = T) ## lavaan 0.6-2 ended normally after 19 iterations ## ## Optimization method NLMINB ## Number of free parameters 4 ## ## Number of observations 90 ## ## Estimator ML ## Model Fit Test Statistic 3.297 ## Degrees of freedom 1 ## P-value (Chi-square) 0.069 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## firesev ~ ## age 0.060 0.012 4.832 0.000 0.060 0.454 ## cover ~ ## firesev -0.084 0.018 -4.611 0.000 -0.084 -0.437 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .firesev 2.144 0.320 6.708 0.000 2.144 0.794 ## .cover 0.081 0.012 6.708 0.000 0.081 0.809 ## ## R-Square: ## Estimate ## firesev 0.206 ## cover 0.191 The key difference from our previous application of lavaan is we now have extra information with which to compute the \\(\\chi^2\\) goodness-of-fit statistic. A quick application of the t-rule: unknowns = 3 variances + 2 path coefficients = 5, knowns = 3 variables, so \\(5 &lt; 3(3+1)/2 = 6\\) leaving us 1 extra degree of freedom. Moreover, we fail to reject the null that the observed and model-implied variance-covariance matrices are significantly different (\\(P = 0.069\\)). Thus, we have achieved adequate fit with this model. Incidentally, we can obtain other fit statistics using the fitMeasures function: fitMeasures(keeley_sem2) ## npar fmin chisq ## 4.000 0.018 3.297 ## df pvalue baseline.chisq ## 1.000 0.069 43.143 ## baseline.df baseline.pvalue cfi ## 3.000 0.000 0.943 ## tli nnfi rfi ## 0.828 0.828 0.771 ## nfi pnfi ifi ## 0.924 0.308 0.945 ## rni logl unrestricted.logl ## 0.943 -176.348 -174.699 ## aic bic ntotal ## 360.696 370.695 90.000 ## bic2 rmsea rmsea.ci.lower ## 358.071 0.160 0.000 ## rmsea.ci.upper rmsea.pvalue rmr ## 0.365 0.101 0.245 ## rmr_nomean srmr srmr_bentler ## 0.245 0.062 0.062 ## srmr_bentler_nomean srmr_bollen srmr_bollen_nomean ## 0.062 0.062 0.062 ## srmr_mplus srmr_mplus_nomean cn_05 ## 0.062 0.062 105.849 ## cn_01 gfi agfi ## 182.093 0.966 0.798 ## pgfi mfi ecvi ## 0.161 0.987 0.126 Woah! We’re certainly not lacking in statistics. Returning to the summary output, we see the same coefficient for \\(firesev ~ age\\) and a new estimate for \\(cover ~ firesev\\). In this case, more severe fires reduce cover (not unexpectedly). Now that we have multiple linkages, we can also compute the indirect effect of age on cover. Recall from Rule 3 of path coefficients that the indirect effects along a compound path are the product of the individual path coefficients: \\(0.454 * -0.437 = -0.198\\). We can obtain this value by modifying the model formula to include these calculations directly. This involves giving a name to the coefficients in the model statement, then adding a new line indicating their product using the operator :=: keeley_formula2.1 &lt;- &#39; firesev ~ B1 * age cover ~ B2 * firesev indirect := B1 * B2 &#39; keeley_sem2.1 &lt;- sem(keeley_formula2.1, keeley) summary(keeley_sem2.1, standardize = T) ## lavaan 0.6-2 ended normally after 19 iterations ## ## Optimization method NLMINB ## Number of free parameters 4 ## ## Number of observations 90 ## ## Estimator ML ## Model Fit Test Statistic 3.297 ## Degrees of freedom 1 ## P-value (Chi-square) 0.069 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## firesev ~ ## age (B1) 0.060 0.012 4.832 0.000 0.060 0.454 ## cover ~ ## firesev (B2) -0.084 0.018 -4.611 0.000 -0.084 -0.437 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .firesev 2.144 0.320 6.708 0.000 2.144 0.794 ## .cover 0.081 0.012 6.708 0.000 0.081 0.809 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## indirect -0.005 0.002 -3.336 0.001 -0.005 -0.198 Indeed, the indirect path coefficient is the same as computed above. Naming coefficients can come in handy when specifying, for example, a fixe values or when they ought to be constrained (see Chapter: Multigroup Modeling). 2.6.3 Testing Alternate Structure using lavaan There is another possible configuration of these variables which includes a directed path between age and cover: keeley sem This type of model tests partial mediation, or the idea that the effect of age is partially mediated by fire severity, but there is all a direct linkage between age and cover. Let’s fit the partial mediation model: keeley_formula3 &lt;- &#39; firesev ~ age cover ~ firesev + age &#39; keeley_sem3 &lt;- sem(keeley_formula3, data = keeley) summary(keeley_sem3, standardize = T) ## lavaan 0.6-2 ended normally after 20 iterations ## ## Optimization method NLMINB ## Number of free parameters 5 ## ## Number of observations 90 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 0 ## Minimum Function Value 0.0000000000000 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## firesev ~ ## age 0.060 0.012 4.832 0.000 0.060 0.454 ## cover ~ ## firesev -0.067 0.020 -3.353 0.001 -0.067 -0.350 ## age -0.005 0.003 -1.833 0.067 -0.005 -0.191 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .firesev 2.144 0.320 6.708 0.000 2.144 0.794 ## .cover 0.078 0.012 6.708 0.000 0.078 0.780 Ah, we have a problem: the model is saturated, so there are no degrees of freedom leftover with which to test model fit. We can, however, test whether this model is more or less supported than the partial mediation model using the \\(\\chi^2\\) difference test: anova(keeley_sem2, keeley_sem3) ## Chi Square Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## keeley_sem3 0 359.4 371.9 0.0000 ## keeley_sem2 1 360.7 370.7 3.2974 3.2974 1 0.06939 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 (Note that the \\(\\chi^2\\) statistic and associated degrees of freedom are still 0 for the model testing partial mediation.) We can see from this output that we fail to reject the null that the models are significantly different (\\(P = 0.069\\)). Because these are nested models, it is also fair to compare them using AIC/BIC. In both cases, the models are deemed equivalent and the more parsimonious model (full mediation) would be preferred. Moreover, examining the output of the model of partial mediation reveals a non-significant effect of age on cover (\\(P = 0.067\\)). Together, these pieces of information would suggest that plant cover is not directly effect by stand age, but rather the effect of age is entirely mediated through the severity of burns. 2.7 References Grace, J. B., &amp; Keeley, J. E. (2006). A structural equation model analysis of postfire plant diversity in California shrublands. Ecological Applications, 16(2), 503-514. "],
["coefficients.html", "3 Coefficients 3.1 Unstandardized and Standardized Coefficients 3.2 Scale Standardization 3.3 Range Standardization 3.4 Binomial Response Models 3.5 Scaling to Other Non-Normal Distributions 3.6 References", " 3 Coefficients 3.1 Unstandardized and Standardized Coefficients Path (or regression) coefficients are the inferential engine behind structural equation modeling, and by extension all of linear and even some non-linear statistics (as we shall see). They relate changes in the dependent variable \\(y\\) to changes in the independent variable \\(x\\), and thus act as a measure of association. In fact, you may recall from the chapter on Global Estimation that, under specific circumstances, path coefficients can be expressed as (partial) correlations, which all scientists are familiar with as a unitless measure of association. They also allow us to generate predictions for new values of \\(x\\) and thus are useful in testing and extrapolating model results. There are two kinds of regression coefficients: unstandardized, or raw coefficients, and standardized coefficients. Unstandardized coefficients are the easiest to derive as they are the default values returned by all statistical programs. In short, they reflect the expected (linear) change in the response with each unit change in the predictor. For a coefficient value \\(\\beta = 0.5\\), for example, a 1 unit change in \\(x\\) there is, on average, an 0.5 unit change in \\(y\\). In models with more than one independent variable (e.g., \\(x1\\), \\(x2\\), etc), the coefficient reflects the expected change in \\(y\\) given the other variables in the model. This implies that the effect of one particular variable controls for the presence of other variables, generally by holding them constant at their mean. This is why such coefficients are referred to as partial regression coefficients, because they reflect the independent (or partial) contributions of any particular variable. One tricky aspect to interpretation involves transformations. When the log-transformation is applied, for example, the relationships between the variable are no longer linear. This means that we have to change our interpretation slightly. When \\(y\\) is log-transformed, the coefficient \\(\\beta\\) is interpreted as a 1 unit change in \\(x\\) leads to a \\((exp(\\beta) - 1) \\times 100%\\) change in \\(y\\). Oppositely, when the independent variable \\(x\\) is log-transformed, \\(\\beta\\) is interpreted as a 1% change in \\(x\\) leads to a \\(\\beta\\) increase in \\(y\\). Finally, when both are transformed, both are expressed in percentages: a 1% change in \\(x\\) leads to a \\((exp(\\beta) - 1) \\times 100%\\) change in \\(y\\). Transformations often confound intrepretation, so it is worth mentioning. In contrast, standardized coefficients are expressed in equivalent units, regardless of the original measurements. Often these are in units of standard deviations of the mean (scale standardization) but, as we shall see shortly, there are other possibilities. The goal of standardization is to increase comparability. In other words, the magnitude of standardized coefficients can be directly compared to make inferences about the relative strength of relationships. In SEM, it is often advised to report both unstandardized and standardized coefficients, because they present different and mutually exclusive information. Unstandardized coefficients contain information about both the variance and the mean, and thus are essential for prediction. Along these lines, they are also useful for comparing across models fit to the same variables, but using different sets of data. Because the most common form of standardization concerns scaling by the sample standard deviations, data derived from different sources have different sample variances and their standardized coefficients are not immediately comparable. Unstandardized coefficients are also most related to the phenomenon of interest in the units that are relevant to the outcome. Imagine telling someone that 1 standard deviation change in nutrient input levels would result in a 6 standard deviation change in water quality. That might seem impressive until it becomes clear that the size of the dataset has reduced the sample variance, and the absoluty relationship reveals only a very tiny change in water quality with each unit change in nutrient levels. Not so impressive anymore. In contrast, standardized effects are useful for comparing the relative magnitude of change associated with different paths in the same model. Care should be taken not to interpret these relationships as the ‘proportion of variance explained’ but rather in terms of relative influence on the mean of the response. By extension, standardization is necessary to compare indirect or compound effects among different paths in the same model. This is because those paths could be measured in very different units. For example, comparing the relative effect of direct vs. indirect pathways in a partially-mediated model. In contrast, comparing the strength of indirect or compound effects across the same path in different models requires unstandardized coefficients, due to the issue of different sample variances raised above. Comparing the same path across different models using standardiezd coefficients would require a demonstration that the sample variances are not significantly different (or that the entire population has been sampled). Thus, both standardized and unstandardized coefficients have their place. Let’s now explore some of the different forms of standardization, and how they can be achieved. 3.2 Scale Standardization The most typical implementation of standardization is placing the coefficients in units of standard deviations of the mean. This is accomplished by scaling the coefficient \\(\\beta\\) by the ratio of the standard deviation of \\(x\\) over the standard deviation of \\(y\\): \\[b = \\beta*\\left( \\frac{sd_x}{sd_y} \\right)\\] This coefficient has the interpretation that, for a 1 standard deviation change in \\(x\\), we expect a \\(b\\) unit standard deviation change in \\(y\\). This standardization can be achieved by Z-transforming the raw data, in which case \\(b\\) is the (partial) correlation between \\(x\\) and \\(y\\) (see Chapter: Global Estimation). Scaling the raw data by subtracting the mean and dividing by the standard deviation lends this standardization its name. Both lavaan and piecewiseSEM return scale-standardized coefficients. lavaan requires a different set of functions or arguments, while piecewiseSEM will do it by default using the functions coefs. coefs has the added benefit in that it can be called on any model object, not just an SEM. Let’s run an example: library(lavaan) ## This is lavaan 0.6-2 ## lavaan is BETA software! Please report any bugs. library(piecewiseSEM) ## ## This is piecewiseSEM version 2.1.0 ## ## ## If you have used the package before, it is strongly recommended you read Section 3 of the vignette(&#39;piecewiseSEM&#39;) to familiarize yourself with the new syntax ## ## Questions or bugs can be addressed to &lt;LefcheckJ@si.edu&gt; set.seed(6) data &lt;- data.frame(y = runif(100), x = runif(100)) xy_model &lt;- lm(y ~ x, data = data) # perform manual standardization beta &lt;- summary(xy_model)$coefficients[2, 1] (beta_std &lt;- beta * (sd(data$x)/sd(data$y))) ## [1] 0.09456659 # now retrieve with piecewiseSEM coefs(xy_model) ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## 1 y x 0.0922 0.098 98 0.9404 0.3493 0.0946 ## ## 1 # and with lavaan xy_formula &lt;- &#39;y ~ x&#39; xy_sem &lt;- sem(xy_formula, data) standardizedsolution(xy_sem) ## lhs op rhs est.std se z pvalue ci.lower ci.upper ## 1 y ~ x 0.095 0.099 0.956 0.339 -0.099 0.288 ## 2 y ~~ y 0.991 0.019 52.991 0.000 0.954 1.028 ## 3 x ~~ x 1.000 0.000 NA NA 1.000 1.000 # also summary(xy_sem, standardize = T) ## lavaan 0.6-2 ended normally after 11 iterations ## ## Optimization method NLMINB ## Number of free parameters 2 ## ## Number of observations 100 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## y ~ ## x 0.092 0.097 0.950 0.342 0.092 0.095 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .y 0.090 0.013 7.071 0.000 0.090 0.991 In all 3 cases, we have achieved a scale-standardized coefficient of \\(b = 0.095\\). Thus, a 1 SD change in \\(x\\) would result in a 0.095 SD change in \\(y\\). 3.3 Range Standardization An alternative to scale standardization is ‘relevant range’ standardization. This approach scales the coefficients over, as the name implies, some relevant range. Typically this is the full range of the data, in which case \\(\\beta\\) can be standardized as follows: \\[b = \\beta * \\frac{max(x) - min(x)}{max(y) - min(y)}\\] The interpretation for the coefficient would then be the expected proportional shift in \\(y\\) along its range given a full shift along its range by \\(x\\). At first, this might seem like a strange form of standardization, but it makes perfect sense in certain cases. For example, consider a binary predictor: 0, 1. In such a case, the relevant range-standardized coefficient is the expected shift in \\(y\\) given the shift from one state (0) to another (1). Or consider a management target such as decreasing nutrient runoff by 10%. Would reducing fertilizer application by 10% of its range yield a 10% reduction in runoff? Such expressions are the currency of some, more applied realms. Perhaps the best application of relevant ranges is in comparing coefficients within a model: rather than dealing in somewhat esoteric quantities of standard deviations, relevant range standardization simply asks which variable causes a greater shift in \\(y\\) along its range. This is a much more digestable concept to most scientists. It may even provide a more fair comparison across the same paths fit to different datasets, if the ranges are roughly similar and/or encompassed in the others. For a worked example, we have now entered fully into the realm of piecewiseSEM–it does not appear as if lavaan has integrated this functionality a of yet. Let’s attempt to scale the results by hand, then compare to the output from coefs with the argument standardize = &quot;range&quot;: #by hand (beta_rr &lt;- beta * (max(data$x) - min(data$x))/(max(data$y) - min(data$y))) ## [1] 0.09806703 coefs(xy_model, standardize = &quot;range&quot;) ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## 1 y x 0.0922 0.098 98 0.9404 0.3493 0.0981 ## ## 1 In both cases, we obtain a \\(b = 0.0981\\) suggesting that a full shift in \\(x\\) along its range would only result in a shift of 10% along the range of \\(y\\). Both scale and relevant range-standardization only apply when the response is normally-distributed. If not, we must make some assumptions in order to obtain standardized coefficients. Let’s start with binomial responses. 3.4 Binomial Response Models Binomial responses are those that are binary (0, 1) such as success or failure, present or absent, and so on. What is unique about them is that they do not have a linear relationship with a predictor \\(x\\). Instead, they are best modeled using a sigmoidal curve. To demonstrate, let’s generate some data, fit a binary model, and plot the predicted relationship: set.seed(44) x &lt;- rnorm(20) x &lt;- x[order(x)] y &lt;- c(rbinom(10, 1, 0.8), rbinom(10, 1, 0.2)) glm_model &lt;- glm(y ~ x, data = data.frame(x = x, y = y), &quot;binomial&quot;) xpred &lt;- seq(min(x), max(x), 0.01) ypred &lt;- predict(glm_model, list(x = xpred), type = &quot;response&quot;) plot(x, y) lines(xpred, ypred) Clearly these data are not linear, and modeling them as such would violate the assumptions of the test. Instead, as you can see, we instead fit them to a binomial distribution using a generalized linear model (GLM). GLMs consist of three parts: (1) the random component, or the expected values of the response based on their underlying distribution, (2) the systematic component that represents the linear combination of predictors, and (3) the link function, which links the expected values of the response (random component) to the linear combination of predictors (systematic component). Basically, the link functions take something inherently non-linear and attempts to linearize it. This can be shown by plotting the predictions on the link-scale: ypred_link &lt;- predict(glm_model, list(x = xpred), type = &quot;link&quot;) plot(xpred, ypred_link) Note how the line is no longer sigmoidal, but straight! For binomial responses, there are two kinds of link functions: logit and probit. We’ll focus on the logit link for now because its more common. With this link, the coefficients are in units of logits or the log odds ratio, which reflect the log of the probability of observing an outcome (1) relative to the probability of not observing it (0). Often these coefficients are reverted to just the odds ratio by taking the exponent, which yields the proportional change in the probablity observing one outcome (1) with a unit change change in the predictor. Say, for example, we have a coefficient \\(\\beta = -0.12\\). A 1 unit change in \\(x\\) would result in \\(exp(-0.12) = 0.88 \\times 100%\\) or 88% reduction in the odds of observing the outcome. The problem is that (log) odds ratios themselves are not comparable across models, and its unclear how they might be standardized, since the coefficient is on the link (linear) scale, while the only variance we can compute is from the raw data, which is on the non-linear scale. Thus, we need to find some sway to obtain estimates of variance on the same scale as the coefficient. One approach is to consider that for every value of \\(x\\), there is an underlying probability distribution of observing a 0 or a 1. The mean of these distributions is where a particular outcome is most likely. Let’s say at low values of \\(x\\) we observe 0, at at high values of \\(x\\) we observe 1. If we order \\(x\\), the mean probabilities give rise to a linear increase in observing 1 with increasing \\(x\\). Here is an illustration of this phenomenon (from Long 1997): latent propensity This linear but latent variable, which we call \\(y^*\\), is therefore related to the observed values of \\(x\\) through a vector of linear coefficients \\(\\beta\\) as in any other linear model: \\[y^*_{i} = x_{i}\\beta + \\epsilon_{i}\\] The problem is, we can never observe this linear underlying or latent propensity, and so we must approximate it. At some value of \\(x\\), this probability is evenly split at 50/50: we call this cutpoint \\(\\tau\\). Below \\(\\tau\\) we are more likely to observe 0 in our example, while above \\(\\tau\\) we are more likely to observe 1. We can relate \\(y\\) to \\(y^*\\) based on whether the observed values fall above or below this cutpoint. Since latent variables are unobserved, we must also make some assumptions about their error variance. In the chapter on Latent Variable Modeling, we often fixed their error variance to 1. In this case, there are theoretically-derived error variances depending on the distribution and the link function: for the probit link, the error variance \\(\\epsilon = 1\\), while for the logit link, \\(\\epsilon = \\pi^2/3\\), both for the binomial distribution. Regardless of the type of standardization, we need to know about the range or variance of the response. With our knowledge of \\(y^*_{i}\\) and the theoretical error variances, we have all the information needed to compute the variance on the link (linear) scale. The variance in \\(y^*\\) is the sum of the variance of the predictions (on the linear scale) plus the theoretical error variance. For a logit link, then: \\[\\sigma_{y^*_{i}}^2 = \\sigma_{x\\beta}^2 + \\pi^2/3\\] The square-root of this quantity gives the standard deviation of \\(SD_{y^*}\\) on the linear scale for use in scale standardization, or alternately, the range of \\(y^*\\) to use in relevant range standardization. There is an alternate method to the ‘latent theoretic approach’, which relies on the proportion of variance explained, or \\(R^2\\). Here, we can express the \\(R^2\\) as the variance of the predicted values (on the non-linear scale) over the variance of the observed values (also on the non-linear scale): \\[R^2 = \\frac{\\sigma_{\\hat{y}}^2}{\\sigma_{y}^2}\\] We can obtain the variance of the observed values as the variance of the predicted values (on the linear scale) over the value of \\(R^2\\). The standard deviation, of course, is the square-root of this value. This method, called the observation-empirical approach, does not require the acknowledgement of any latent variables or theoretical error variances, but does require an acceptance of this is a valid measurement of \\(R^2\\) (which some consider it not, as GLM estimation is based on deviance, not variance, and thus this statistic is not equivalent). It also does not provide a measure of the range of \\(y\\) although we can assume, based on sampling theory, that is \\(6 * \\sigma_{y}\\). Let’s revisit our earlier GLM example and construct standardized coefficients: # get beta from model beta &lt;- summary(glm_model)$coefficients[2, 1] preds &lt;- predict(glm_model, type = &quot;link&quot;) # linear predictions # latent theoretic sd.ystar &lt;- sqrt(var(preds) + (pi^2)/3) # for default logit-link beta_lt &lt;- beta * sd(x)/sd.ystar # observation empirical R2 &lt;- cor(y, predict(glm_model, type = &quot;response&quot;))^2 # non-linear predictions sd.yhat &lt;- sqrt(var(preds)/R2) beta_oe &lt;- beta * sd(x)/sd.yhat # obtain using `coefs` coefs(glm_model, standardize.type = &quot;latent.linear&quot;); beta_lt ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## 1 y x -2.0975 0.9664 18 -2.1703 0.03 -0.8122 ## ## 1 * ## [1] -0.8121808 coefs(glm_model, standardize.type = &quot;Menard.OE&quot;); beta_oe ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## 1 y x -2.0975 0.9664 18 -2.1703 0.03 -0.6566 ## ## 1 * ## [1] -0.6565602 We see that both approaches produce coefficients, and they are the same as returned by the coefs function in piecewiseSEM (with the appropriate argument). You’ll note that the observation-empirical approach yields a smaller coefficient than the latent-theoretic. This is because the former approach is influenced by the fact that it is based on the relationship between a linear approximation (predictions) of a non-linear variable (raw values), introducing a loss of information. The latent theoretic approach also suffers from a loss of information from use of a distribution-specific but theoretically-derived error variance, which may or may not approach the true error variance (which is unknowable). Either way, both kinds of standardization are not without their drawbacks, but both provide potentially useful information in being able to compare linear and now linearized standardized coefficients. 3.5 Scaling to Other Non-Normal Distributions As it turns out, the latent-theoretic approach has one further benefit: we can extend it to other distributions (as they all have their own theoretical error variances) and mixed-effects models where we must also incorporate the random components. [content to come] 3.6 References Grace, J. B., Johnson, D. J., Lefcheck, J. S., &amp; Byrnes, J. E. (2018). Quantifying relative importance: computing standardized effects in models with binary outcomes. Ecosphere, 9(6), e02283. Scott Long, J. (1997). Regression models for categorical and limited dependent variables. Advanced quantitative techniques in the social sciences, 7. "],
["categorical-variables.html", "4 Categorical Variables 4.1 Introduction to Exogenous Categorical Variables 4.2 Exogenous Categorical Variables as Marginal Means 4.3 Exogenous Categorical Variables as Marginal Means: A Worked Example 4.4 Endogenous Categorical Variables 4.5 References", " 4 Categorical Variables 4.1 Introduction to Exogenous Categorical Variables While most examples using SEM consider continuous variables, it is often the case that the variables are discrete. These include binary (yes/no, failure/success, etc.), nominal (site 1, site 2), or ordinal levels (small &lt; medium &lt; large). There are two cases: categorical variables as exogenous or as endogenous. We will deal with the simpler case of exogenous categorical variables first, as they pose not so much of a computational issue, but a conceptual one. A linear regression predicting y has the following standard form: \\[y = \\alpha + \\beta_{1}*x_{1} + \\epsilon\\] where \\(\\alpha\\) is the intercept, \\(\\beta_{1}\\) is the slope of the effect of \\(x\\) on y, and \\(\\epsilon\\) is the residual error. When \\(x\\) is continuous, the intercept \\(\\alpha\\) is intepreted as the value of y when \\(x\\) = 0. All good. For categorical factors, the intercept \\(\\alpha\\) has a different interpretation. Consider a value of \\(x\\) with \\(k\\) levels. Since the levels of \\(x\\) are discrete and can never assume a value of 0, \\(\\alpha\\) is instead the mean value of y at the ‘reference’ level of \\(x\\). (In R, the reference level is the first level alphabetically, although this can be set manually.) The regression coefficients \\(\\beta_{k}\\) are therefore the effect of each other level relative to the reference level. So for \\(k\\) levels, there are \\(k - 1\\) coefficients estimated with the additional \\(\\alpha\\) term reflecting the \\(k\\)th level. Another way to think about this phenomenon is using so-called ‘dummy’ variables. Imagine each level was broken into a separate variable with a value of 0 or 1: a two-level factor with levels “a” and “b” would then become two factors “a” and “b” each with the levels 0 or 1. (In R, this would mean transposing rows as columns.) Now imagine setting all the values of these dummy variables to 0 to estimate the intercept: this would imply the total absence of the factor, which is not a state. Another way of thinking about this is that the dummy variables are linearly dependent: if “a = 1” then by definition “b = 0” as the response variable cannot occupy the two states simultaneously. Hence the need to set one level as the reference, so that the effect of “a” can be interpreted relative to the absence of “b”. This behavior present a challenge for path diagrams: there is not a single coefficient for the path from \\(x\\) -&gt; y, nor are there enough coefficients to populate a separate arrow for each level of \\(x\\) (because one level must serve as the reference). There are a few potential solutions: for binary variables, set the values as 0 or 1 and model as numeric, which would yield a single coefficient. for ordinal varaibles, set the values depending on the order of the factor, e.g., small = 1 &lt; medium = 2 &lt; large = 3, and then model as numeric, which would yield a single coefficient. For both of these approaches, the coefficients will be interpreted as moving from one state (0) to another (1), or from one level (1) to the next (2). create dummary variables for each level: this is procedurally the same as above (splitting levels into \\(k\\) - 1 separate variables that occupy 0/1). The key here is not to create \\(k\\) variables, to avoid the issue raised above about dependence among predictors. This is the default behavior of lavaan. This approach becomes prohibitive with large number of categories and can greatly increase model complexity. Moreover, each level is treated as an independent variable in tests of direct separation, and thus will inflate the degrees of freedom for the test. for suspected interactions with categorical variables, a multigroup analysis is required. In this case, the same model is fit for each level of the factor, with potentially different coefficients (see Chapter: Multigroup Models). test for the effect of the categorical variable using ANOVA, but do not report a coefficient. This approach would indicate whether a factor is important, but omits important information about the direction and magnitude of change. For example, does a significant treatment effect imply an increase or decrease in the response, and by how much? For this reason, such an approach is not ideal. A alternate approach draws on this final point, and involves testing and reporting the model-estimated, or marginal, means. 4.2 Exogenous Categorical Variables as Marginal Means All models can be used for prediction. In multiple regression, the predicted values of one variable are often computed while holding the values of other variables at their mean. Marginal means are the mean of these predicted values. In other words, it is the expected value of one variable given the other variables in the model. For categorical variables, marginal means are particularly useful because they provide an estimated mean for each level of each factor. Consider a simple example with a single response and two groups “a” and “b”: set.seed(111) dat &lt;- data.frame(y = runif(100), group = letters[1:2]) model &lt;- lm(y ~ group, dat) summary(model) ## ## Call: ## lm(formula = y ~ group, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.48473 -0.21466 -0.01238 0.19715 0.54995 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.44677 0.03871 11.541 &lt;2e-16 *** ## groupb 0.08551 0.05475 1.562 0.122 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2737 on 98 degrees of freedom ## Multiple R-squared: 0.02429, Adjusted R-squared: 0.01433 ## F-statistic: 2.44 on 1 and 98 DF, p-value: 0.1215 Note that the summary output gives a simple coefficient, which is the effect of group “b” on y in the absence of group “a”. The intercept is simply the average of y in group “a”: summary(model)$coefficients[1, 1] ## [1] 0.4467679 mean(subset(dat, group == &quot;a&quot;)$y) ## [1] 0.4467679 The marginal means are the expected value of y in group “a” or group “b”. predict(model, data.frame(group = &quot;a&quot;)) ## 1 ## 0.4467679 predict(model, data.frame(group = &quot;b&quot;)) ## 1 ## 0.53228 Because this is a simple linear regression, these values are simply the means of the two subsets of the data, because they are not controlling for other covariates: mean(subset(dat, group == &quot;a&quot;)$y) ## [1] 0.4467679 mean(subset(dat, group == &quot;b&quot;)$y) ## [1] 0.53228 Let’s see what happens we add a continuous covariate: dat$x &lt;- runif(100) model &lt;- update(model, . ~ . + x) Here, the marginal mean must be evaluated while holding the covariate \\(x\\) at its mean value: predict(model, data.frame(group = &quot;a&quot;, x = mean(dat$x))) ## 1 ## 0.4450597 mean(subset(dat, group == &quot;a&quot;)$y) ## [1] 0.4467679 You’ll note that this value is now different than the mean of the subset of the data because, again, it controls for the presence of \\(x\\). This procedure gets increasingly complicated with both the number of factor levels and the number of covariates. The emmeans package provides an automated way to compute marginal means: library(emmeans) emmeans(model, specs = &quot;group&quot;) # where specs is the variable or list of variables whose means are to be estimated ## group emmean SE df lower.CL upper.CL ## a 0.4450597 0.03893785 97 0.3677788 0.5223405 ## b 0.5339882 0.03893785 97 0.4567074 0.6112691 ## ## Confidence level used: 0.95 You’ll note that the output value gives the same as using the predict function above, but also returns the marginal mean for group “b” while also controlling for \\(x\\): predict(model, data.frame(group = &quot;b&quot;, x = mean(dat$x))) ## 1 ## 0.5339882 and so is a handy wrapper for complex models. Coupled with ANOVA to test for the significance of the categorical variable, the marginal means provide key information that is otherwise lacking, namely how the response value changes based on the factor level. In does not, however, allow for prediction in the same way a model coefficient does. The emmeans package provides additional functionality by conducting post-hoc tests of differences among the means of each factor level: emmeans(model, list(pairwise ~ group)) ## $`emmeans of group` ## group emmean SE df lower.CL upper.CL ## a 0.4450597 0.03893785 97 0.3677788 0.5223405 ## b 0.5339882 0.03893785 97 0.4567074 0.6112691 ## ## Confidence level used: 0.95 ## ## $`pairwise differences of group` ## contrast estimate SE df t.ratio p.value ## a - b -0.08892852 0.05520893 97 -1.611 0.1105 You’ll note a second output which is the pairwise contrast between the means of groups “a” and “b” with an associated significance test. These pairwise Tukey tests provide the final level of information, which is whether the response in each level varies significantly from the other levels. The coefs function in piecewiseSEM adopts a two-tiered approach by first computing the significance of the categorical variable using ANOVA, and then reports the marginal means and post-hoc tests: library(piecewiseSEM) ## ## This is piecewiseSEM version 2.1.0 ## ## ## If you have used the package before, it is strongly recommended you read Section 3 of the vignette(&#39;piecewiseSEM&#39;) to familiarize yourself with the new syntax ## ## Questions or bugs can be addressed to &lt;LefcheckJ@si.edu&gt; coefs(model) ## Response Predictor Estimate Std.Error DF Crit.Value P.Value ## 1 y x 0.0567 0.093 97 0.6094 0.5437 ## 2 y group - - 1 0.1957 0.1105 ## 3 group[a] mean= 0.4451 0.0389 97 - - ## 4 group[b] mean= 0.534 0.0389 97 - - ## Std.Estimate ## 1 0.0613 ## 2 - ## 3 - a ## 4 - a In this output, the significance test from the ANOVA is reported in the row corresponding to the group effect, and below that are the marginal means for each level of the grouping factor. Finally, the results of the post-hoc test are given using letters at the end of the rows reporting the marginal means. In this case, the same letter indicates no significant difference among the group levels. This solution provides a measure of whether the path between the exogenous categorical variable and the respones is significant, as well as parameters for each level in the form of the model-estimated marginal means. 4.3 Exogenous Categorical Variables as Marginal Means: A Worked Example Let’s consider an example from Bowen et al. (2017). In this study, the authors were interested in how different microbiomes of the salt marsh plant Phragmites australis drive ecosystem functioning, and ultimately the production of aboveground biomass. In this case, they considered three microbial communities: those from a native North American lineage, from Gulf Coast lineage, and an introduced lineage. There were additional genotypes within each community type, necessitating the application of random effects to account for intraspecific variation. We will fit a simplified version of their full path diagram, focusing only on aboveground biomass (although they also test the effect on belowground biomass). bowen_sem In this case, the variable “Phragmites status” corresponds to the three community types, and can’t be represented using a single coefficient. Thus, the marginal-means approach is ideal to elucidate the effect of each community type on both proximate and ultimate ecosystem properties. Let’s read in the data and construct the model: bowen &lt;- read.csv(&quot;./data/bowen.csv&quot;) bowen &lt;- na.omit(bowen) library(nlme) bowen_sem &lt;- psem( lme(observed_otus ~ status, random = ~1|Genotype, data = bowen, method = &quot;ML&quot;), lme(RNA.DNA ~ status + observed_otus, random = ~1|Genotype, data = bowen, method = &quot;ML&quot;), lme(below.C ~ observed_otus + status, random = ~1|Genotype, data = bowen, method = &quot;ML&quot;), lme(abovebiomass_g ~ RNA.DNA + observed_otus + belowCN + status, random = ~1|Genotype, data = bowen, method = &quot;ML&quot;), data = bowen ) And let’s retrieve the output: summary(bowen_sem, .progressBar = F) ## ## Structural Equation Model of bowen_sem ## ## Call: ## observed_otus ~ status ## RNA.DNA ~ status + observed_otus ## below.C ~ observed_otus + status ## abovebiomass_g ~ RNA.DNA + observed_otus + belowCN + status ## ## AIC BIC ## 67.877 125.138 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Estimate Std.Error DF Crit.Value P.Value ## observed_otus ~ belowCN + ... 3.3036 2.2934 57 1.4405 0.1552 ## RNA.DNA ~ belowCN + ... 0.0002 0.0002 56 1.3740 0.1749 ## below.C ~ belowCN + ... 0.0171 0.0063 56 2.7225 0.0086 ## below.C ~ RNA.DNA + ... -0.5383 3.0545 56 -0.1762 0.8607 ## abovebiomass_g ~ below.C + ... -0.0357 0.0787 54 -0.4540 0.6516 ## ## ## ## ** ## ## ## ## Global goodness-of-fit: ## ## Fisher&#39;s C = 17.877 with P-value = 0.057 and on 10 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value ## observed_otus status - - 2 5.9589 ## status[native] mean= 2258.6564 105.8178 12 - ## status[introduced] mean= 2535.07 131.2216 14 - ## status[invasive] mean= 2541.4984 56.6887 12 - ## RNA.DNA observed_otus 0 0 57 2.1583 ## RNA.DNA status - - 2 9.348 ## status[invasive] mean= 0.7112 0.0118 12 - ## status[introduced] mean= 0.7305 0.0264 14 - ## status[native] mean= 0.7844 0.0216 12 - ## below.C observed_otus 9e-04 3e-04 57 2.6546 ## below.C status - - 2 17.1995 ## status[introduced] mean= 42.6366 0.3673 14 - ## status[invasive] mean= 43.4004 0.1594 12 - ## status[native] mean= 44.4975 0.3056 12 - ## abovebiomass_g RNA.DNA -1.8517 1.8893 55 -0.9801 ## abovebiomass_g observed_otus -2e-04 2e-04 55 -0.7521 ## abovebiomass_g belowCN 0.005 0.0041 55 1.2026 ## abovebiomass_g status - - 2 12.9519 ## status[native] mean= 1.7489 0.2206 12 - ## status[invasive] mean= 1.8807 0.1041 12 - ## status[introduced] mean= 2.7024 0.232 14 - ## P.Value Std.Estimate ## 0.0508 - ## - - a ## - - a ## - - a ## 0.0351 0.135 * ## 0.0093 - ** ## - - a ## - - ab ## - - b ## 0.0103 0.2913 * ## 2e-04 - *** ## - - a ## - - a ## - - b ## 0.3313 -0.1428 ## 0.4552 -0.0905 ## 0.2343 0.1356 ## 0.0015 - ** ## - - a ## - - a ## - - b ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## Individual R-squared: ## ## Response method Marginal Conditional ## observed_otus none 0.10 0.19 ## RNA.DNA none 0.31 0.81 ## below.C none 0.26 0.32 ## abovebiomass_g none 0.22 0.28 In this case, it appears that the model fits the data well enough (\\(P = 0.057\\)). The linkage between microbial community type (status) and richness is non-significant, but the other paths are significant. Examination of the marginal means indicates microbial activity (RNA/DNA) and belowground carbon are generally highest in Phragmites with native microbial communities based on the post-hoc tests. However, none of these properties appear to influence the ultimate production of biomass. Rather, that property appears to be entirely controlled by the plant microbiome: those with the introduced microbial community have significantly higher aboveground biomass based on the post-hoc tests after controlling for microbial activity and soil nutrients. (In the full article, they draw the same inference for belowground biomass.) Thus, despite a multi-level categorical predictor (microbiome status), the two-step procedure of ANOVA and calculation of marginal means reveals a mechanistic understanding of the drivers of plant biomass in this species. 4.4 Endogenous Categorical Variables Endogenous categorical variables are far trickier, and at the moment, are not implemented in piecewiseSEM. In the case of endogenous categorical variables in a piecewise framework, there are really only two solutions: for binary variables, set the values as 0 or 1 and model as numeric, which would yield a single coefficient. for ordinal variables, set the values depending on the order of the factor, e.g., small = 1 &lt; medium = 2 &lt; large = 3, and then model as numeric, which would yield a single coefficient. Nominal variables (i.e., levels are not ordered) cannot be modeled at this time. One could approach this through the application of multinomial regression. lavaan provides a robust alternative in the form of confirmatory factor analysis (see http://lavaan.ugent.be/tutorial/cat.html). 4.5 References Bowen, J. L., Kearns, P. J., Byrnes, J. E., Wigginton, S., Allen, W. J., Greenwood, M., … &amp; Meyerson, L. A. (2017). Lineage overwhelms environmental conditions in determining rhizosphere bacterial community structure in a cosmopolitan invasive plant. Nature communications, 8(1), 433. "],
["multigroup-analysis.html", "5 Multigroup Analysis 5.1 Introduction to Multigroup Analysis 5.2 Multigroup Analysis using Global Estimation 5.3 Multigroup Analysis using Local Estimation 5.4 Grace &amp; Jutila (1999): A Worked Example 5.5 References", " 5 Multigroup Analysis 5.1 Introduction to Multigroup Analysis Often in ecology we wish to compare the results from two or more groups. These groups could reflect experimental treatments, different sites, different sexes, or any number of types of organization. The ultimate goal of such an analysis is to ask whether the relationships among predictor and response variables vary by group. For example, does the effect of pesticide on invertebrate biomass change as function of where the pesticide is applied? Historically, such a goal would be captured through the application of a statistical interaction. In the above example, the statistical model might be something like: \\[biomass = pesticide * location\\] Here, a significant interaction between \\(pesticide \\times location\\) would indicate that the effect of pesticide applicaiton on invertebrate biomass varies by location. It would of course then be up to the author to use their knowledge of the system to speculate why this is. In the event that the interaction is not statistically significant, then the author would conclude that the effect of pesticide is invariant to location, and could go on to interpret the main effect of pesticide. In this situation, they are able to generalize the effects of pesticide such that it is expected to have the same magnitude of effect regardless of where it is applied. A multigroup model is essentially the same principle, but instead of focusing on a single response, the interaction is applied across a network of variables. In other words, it asks if not just one, but all coefficients are the same or different across groups while leveraging the entirety of the data across groups. In a sense, it can be thought of as a “model-wide” interaction, and in fact, this is how we will treat it later using a piecewise approach. One could simply fit the same model structure to different subsets of the data, but this would not allow you to identify which paths change based on the group and which do not. Rather, one would have to compare the magnitude and standard errors of each pair of coefficients manually, rather than through a formal statistical procedure. The application of multigroup models differs between a global estimation (i.e., variance-covariance-based SEM) and local estimation (i.e., piecewise SEM), but adhere to the same idea of identifying which paths have the same effect across groups, and which paths vary depending on the group. In this chapter, we will work through both approaches, and then compare/contrast the output. 5.2 Multigroup Analysis using Global Estimation Multigroup modeling using global estimation begins with the estimation of two models: one in which all parameters are allowed to differ between groups, and one in which all parameters are fixed to those obtained from analysis of the pooled data across groups. We call the first model the “free” model since all parameters are free to vary, and the second the “constrained” model since each path, regardless of its group, is constrained to a single value determined by the entire dataset. If the two models are not significantly different, and the latter fits the data well, then one can assume there is no variation in the path coefficients by group and multigroup approach is not necessary. If they are, then the exercise shifts towards understanding which paths are the same and which are different. This is achieved by sequentially constraining the coefficients of each path and re-fitting the model. Let’s illustrate this procedure using a random example using three variables (\\(x\\), \\(y\\), and \\(z\\)) in two groups (“a” and “b”): set.seed(111) dat &lt;- data.frame(x = runif(100), group = rep(letters[1:2], each = 50)) dat$y &lt;- dat$x + runif(100) dat$z &lt;- dat$y + runif(100) In this example, we suppose a simple mediation model: \\(x -&gt; y -&gt; z\\), and that all three variables are correlated to some degree so that this path model makes sense. We can use lavaan to fit the “free” model. The key is allowing the coefficients to vary by specifying the group = argument. multigroup.model &lt;- &#39; y ~ x z ~ y &#39; library(lavaan) ## This is lavaan 0.6-2 ## lavaan is BETA software! Please report any bugs. multigroup1 &lt;- sem(multigroup.model, dat, group = &quot;group&quot;) We can then obtain the summary of the multigroup analysis: summary(multigroup1) ## lavaan 0.6-2 ended normally after 38 iterations ## ## Optimization method NLMINB ## Number of free parameters 12 ## ## Number of observations per group ## a 50 ## b 50 ## ## Estimator ML ## Model Fit Test Statistic 0.092 ## Degrees of freedom 2 ## P-value (Chi-square) 0.955 ## ## Chi-square for each group: ## ## a 0.049 ## b 0.043 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## ## Group 1 [a]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## y ~ ## x 0.771 0.163 4.734 0.000 ## z ~ ## y 1.080 0.126 8.577 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.684 0.088 7.745 0.000 ## .z 0.463 0.140 3.313 0.001 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.080 0.016 5.000 0.000 ## .z 0.092 0.018 5.000 0.000 ## ## ## Group 2 [b]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## y ~ ## x 1.240 0.135 9.182 0.000 ## z ~ ## y 0.897 0.086 10.465 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.349 0.078 4.460 0.000 ## .z 0.612 0.092 6.654 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.082 0.016 5.000 0.000 ## .z 0.081 0.016 5.000 0.000 Note that, unlike the typical lavaan output, the printout is now organized by group, with separate coefficients for each path in each group. Because this model is allowed to vary, the coefficient for the \\(x -&gt; y\\) path in group “a” is different, for example, from that reported for group “b”. Next, we fit the constrained model by specifying the additional argument group.equal = c(&quot;intercepts&quot;, &quot;regressions&quot;). This argument fixes both the intercepts and path coefficients in each groups to be the same. multigroup1.constrained &lt;- sem(multigroup.model, dat, group = &quot;group&quot;, group.equal = c(&quot;intercepts&quot;, &quot;regressions&quot;)) summary(multigroup1.constrained) ## lavaan 0.6-2 ended normally after 29 iterations ## ## Optimization method NLMINB ## Number of free parameters 12 ## Number of equality constraints 4 ## ## Number of observations per group ## a 50 ## b 50 ## ## Estimator ML ## Model Fit Test Statistic 9.951 ## Degrees of freedom 6 ## P-value (Chi-square) 0.127 ## ## Chi-square for each group: ## ## a 5.541 ## b 4.410 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## ## Group 1 [a]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## y ~ ## x (.p1.) 1.046 0.108 9.678 0.000 ## z ~ ## y (.p2.) 0.960 0.072 13.413 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .y (.p6.) 0.499 0.061 8.219 0.000 ## .z (.p7.) 0.570 0.078 7.283 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.087 0.017 5.000 0.000 ## .z 0.094 0.019 5.000 0.000 ## ## ## Group 2 [b]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## y ~ ## x (.p1.) 1.046 0.108 9.678 0.000 ## z ~ ## y (.p2.) 0.960 0.072 13.413 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .y (.p6.) 0.499 0.061 8.219 0.000 ## .z (.p7.) 0.570 0.078 7.283 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.089 0.018 5.000 0.000 ## .z 0.083 0.017 5.000 0.000 This output is slightly different from the first: the coefficients are reported by group, but they are now the same between groups (\\(x -&gt; y\\) in group “a” = \\(x -&gt; y\\) in group “b”). The constrained paths are indicated by a parenthetical next to the path (e.g., (.p1.) for path 1). Both the constrained and unconstrainted models fit the data well based on the Chi-squared statistic, and we can formally compare the two models using a Chi-squared difference test: anova(multigroup1, multigroup1.constrained) ## Chi Square Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff ## multigroup1 2 95.392 126.65 0.0921 ## multigroup1.constrained 6 97.251 118.09 9.9508 9.8588 4 ## Pr(&gt;Chisq) ## multigroup1 ## multigroup1.constrained 0.04288 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The significant P-value implies that the free and constrained models are significantly different. In other words, some paths vary while others do not. If the models were not significantly different, then one would conclude that the constrained model is equivalent to the free model. In other words, the coefficients would not vary by group and it would be fair to analyze the pooled data in a single model. However, this is the not the case for this example, and we can now undergo the processing of introducing and releasing constraints to try and identify which path varies between groups. In this simplified example, we have two choices: \\(x -&gt; y\\), and \\(y -&gt; z\\). Let’s focus on \\(x -&gt; y\\) first. We can introduce a single constraint by modifying the model formula and re-fitting the model: multigroup.model2 &lt;- &#39; y ~ c(&quot;b1&quot;, &quot;b1&quot;) * x z ~ y &#39; multigroup2 &lt;- sem(multigroup.model2, dat, group = &quot;group&quot;) The string c(&quot;b1&quot;, &quot;b1&quot;) gives the path the name b1 and ensures the coefficient is equal between the two groups (hence the two entries). If we use a Chi-squared difference test as before: anova(multigroup1, multigroup2) ## Chi Square Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## multigroup1 2 95.392 126.65 0.0921 ## multigroup2 3 98.188 126.84 4.8881 4.796 1 0.02853 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We find that the models are still significantly different, implying that the path between \\(x -&gt; y\\) should not be constrained, and that it should be left to vary among groups. We can repeat this exercise with the second path, \\(y -&gt; z\\): multigroup.model3 &lt;- &#39; y ~ x z ~ c(&quot;b2&quot;, &quot;b2&quot;) * y &#39; multigroup3 &lt;- sem(multigroup.model3, dat, group = &quot;group&quot;) summary(multigroup3) ## lavaan 0.6-2 ended normally after 34 iterations ## ## Optimization method NLMINB ## Number of free parameters 12 ## Number of equality constraints 1 ## ## Number of observations per group ## a 50 ## b 50 ## ## Estimator ML ## Model Fit Test Statistic 1.523 ## Degrees of freedom 3 ## P-value (Chi-square) 0.677 ## ## Chi-square for each group: ## ## a 1.031 ## b 0.492 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## ## Group 1 [a]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## y ~ ## x 0.771 0.163 4.734 0.000 ## z ~ ## y (b2) 0.955 0.071 13.389 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.684 0.088 7.745 0.000 ## .z 0.596 0.087 6.858 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.080 0.016 5.000 0.000 ## .z 0.093 0.019 5.000 0.000 ## ## ## Group 2 [b]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## y ~ ## x 1.240 0.135 9.182 0.000 ## z ~ ## y (b2) 0.955 0.071 13.389 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.349 0.078 4.460 0.000 ## .z 0.557 0.080 6.974 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .y 0.082 0.016 5.000 0.000 ## .z 0.082 0.016 5.000 0.000 anova(multigroup1, multigroup3) ## Chi Square Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## multigroup1 2 95.392 126.65 0.0921 ## multigroup3 3 94.823 123.48 1.5230 1.4309 1 0.2316 In this case, there is not a significant difference between the two models, implying that the is no difference in the fit of the constrained model and the unstrained model, and that this constraint is valid. Thus, if we were to select a model from which to draw inference, we would select the third model in which \\(x -&gt; y\\) is allowed to vary and \\(y -&gt; z\\) is constrained among groups. It is key to note that this model also fits the data well based on the \\(\\chi^2\\) statistic; if not, then like all poor-fitting path models (multigroup or otherwise), it would be unwise to present and draw conclusions from it. This exercise of relaxing and imposing constraints is potentially very exploratory and could become exhaustive with more complicated models (i.e., one with lots of paths to potentially constrain/relax). Users should refrain from constraining and relaxing all paths and then choosing the most parsimonious model. Instead, choosing which paths to constrain should be motivated by the question: for example, we might expect some effects to be universal (e.g., temperature on metabolic rate) but not others (e.g., the effect of pesticide may vary depending on the history of application at various sites). It is also important to note that sample size must be sufficiently large to estimate all the parameters, but this is true for all structural equation models. Critically, the degrees of freedom for the model do not change based on the number of groups: because coefficients are estimated from independent variance-covariance matrices for each group, they do not constrain the complexity of the model per se. Standardized coefficients also present a challenge. Because variances are likely to be unequal among groups, the standardized coefficient must be computed on a per group basis, even if the unstandardized coefficient is constrained to the global value. Both packages for SEM will do this automatically, so you may notice that the standardized solutions may vary even among constrained paths. 5.3 Multigroup Analysis using Local Estimation The goal of multigroup analysis using local estimation is identical to that of global estimation: to identify whether a single global model is sufficient to describe the data, or whether some or all paths vary by some grouping variable. The difference lies in execution: while lavaan is a back-and-forth manual process of relaxing and constraining paths, piecewiseSEM tests constraints and automatically selects the best output for your data. The upside is that the arduous and somewhat cumbersome process of specifying constraints is taken care of; the downside is that constraining particular paths is not possible at this time. This means that it is not currently possible to manually set constraints. The first step in the local estimation process is to implement a model-wide interaction. In other words, every term in the model interacts with the grouping variable. If the interaction is significant, then the path varies by group; if not, then the path takes on the estimate from the global model. In this way, the piecewise multigroup procedure breaks down into a series of classical interaction terms. Consider our previous example: \\(x -&gt; y -&gt; z\\) and the groups “a” and “b”. In a piecewise approach, we would first model the interaction between \\(x \\times group\\), and between \\(y \\times group\\): anova(lm(y ~ x * group, dat)) ## Analysis of Variance Table ## ## Response: y ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## x 1 8.2740 8.2740 97.9518 2.475e-16 *** ## group 1 0.2772 0.2772 3.2811 0.07321 . ## x:group 1 0.3974 0.3974 4.7051 0.03254 * ## Residuals 96 8.1091 0.0845 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 In this case, the first interaction between \\(x \\times group\\) in predicting \\(y\\) is significant, indicating the effect of \\(x\\) on \\(y\\) depends on \\(group\\). We would then estimate the effect of \\(x\\) and \\(y\\) for each subset of the data, and report the coefficients separately. This situation is analogous to allowing the path to vary freely by group. anova(lm(z ~ y * group, dat)) ## Analysis of Variance Table ## ## Response: z ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## y 1 15.8899 15.8899 176.3764 &lt;2e-16 *** ## group 1 0.0366 0.0366 0.4066 0.5252 ## y:group 1 0.1271 0.1271 1.4107 0.2379 ## Residuals 96 8.6487 0.0901 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The second interaction between \\(y \\times group\\) in predicting \\(z\\) is non-significant, indicating that the effect of \\(y\\) on \\(z\\) does not depend on \\(group\\) We would then estimate the effect of \\(y\\) on \\(z\\) given the entire dataset, and report that single coefficient across all groups. The implementation of this approach in piecewiseSEM is very straightforward: first, build the model using psem, then use the function multigroup to perform the multigroup analysis: library(piecewiseSEM) ## ## This is piecewiseSEM version 2.1.0 ## ## ## If you have used the package before, it is strongly recommended you read Section 3 of the vignette(&#39;piecewiseSEM&#39;) to familiarize yourself with the new syntax ## ## Questions or bugs can be addressed to &lt;LefcheckJ@si.edu&gt; pmodel &lt;- psem( lm(y ~ x, dat), lm(z ~ y, dat) ) The multigroup function has an argument group = which, as in lavaan, accepts the column name of the grouping factor: (pmultigroup &lt;- multigroup(pmodel, group = &quot;group&quot;)) ## ## Structural Equation Model of pmodel ## ## Groups = group [ a, b ] ## ## --- ## ## Global goodness-of-fit: ## ## Fisher&#39;s C = 0.301 with P-value = 0.86 and on 2 degrees of freedom ## ## --- ## ## Model-wide Interactions: ## ## Response Predictor Test.Stat DF P.Value ## y x:group 0.4 1 0.0325 * ## z y:group 0.1 1 0.2379 ## ## y -&gt; z constrained to the global model ## ## --- ## ## Group [a] coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## y x 0.7712 0.1662 48 4.6387 0 0.5563 ## z y 0.9652 0.0726 98 13.2931 0 0.6895 ## ## *** ## c *** ## ## Group [b] coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## y x 1.2404 0.1379 48 8.9963 0 0.7923 ## z y 0.9652 0.0726 98 13.2931 0 0.8914 ## ## *** ## c *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 c = constrained If we examine the output, we see the output table of model-wide interactions. Its important to note that the package uses car::Anova with type = &quot;III&quot; sums-of-squares to estimate the interactions by default, but other types (e.g., type II) are accepted using the test.type = argument. As above, only the path from x -&gt; y is significantly different among groups. In this case, the function explicitly reports that the path y -&gt; z constrained to the global model. Next, as in lavaan, are the coefficient tables for each group. Values that have been constrained are the same between the two models, while the unconstrained path from \\(x -&gt; y\\) is different between groups “a” and “b”. Its important to note that the standardized coefficients do differ for each group even though the paths are constrained. Again, this is because the variance differs between groups. Thus the standardization: $$\\beta_{std} = \\beta*\\left( \\frac{sd_{x}}{sd_{y}} \\right)$$ must consider only the standard deviation of x and y from their respective groups, even though \\(\\beta\\) is derived from the entire dataset. Finally, near the top is the global goodness-of-fit test based on Fisher’s C. In this case, global constraints have been added as offset to the tests of directed separation. For comparison’s sake, let’s look at the output from the lavaan multigroup model and the piecewiseSEM one: multigroup3 ## lavaan 0.6-2 ended normally after 34 iterations ## ## Optimization method NLMINB ## Number of free parameters 12 ## Number of equality constraints 1 ## ## Number of observations per group ## a 50 ## b 50 ## ## Estimator ML ## Model Fit Test Statistic 1.523 ## Degrees of freedom 3 ## P-value (Chi-square) 0.677 ## ## Chi-square for each group: ## ## a 1.031 ## b 0.492 pmultigroup$group.coefs ## $a ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## 1 y x 0.7712 0.1662 48 4.6387 0 0.5563 ## 2 z y 0.9652 0.0726 98 13.2931 0 0.6895 ## ## 1 *** ## 2 c *** ## ## $b ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## 1 y x 1.2404 0.1379 48 8.9963 0 0.7923 ## 2 z y 0.9652 0.0726 98 13.2931 0 0.8914 ## ## 1 *** ## 2 c *** You’ll note that the outputs are roughly equivalent (owing to slight differences in the estimation procedures for each package). Critically, the coefficient for the path from \\(x -&gt; y\\) is the same in both groups. 5.4 Grace &amp; Jutila (1999): A Worked Example Let’s now turn to a real example from Grace &amp; Jutila (1999). While the original paper fit a far more complicated model than we will, the following simplified model demonstrates the approach well. In their study, the authors were interested in the controls of on plant species’ density in Finnish meadows. In this worked example, we will consider only elevation and total biomass in their effects on density, plus an effect of elevation on biomass: jutila_sem Moreover, they repeated their observations in two treatments: grazed and ungrazed meadows. Grazing will serve as the grouping variable for our multigroup analysis. The data are included in piecewiseSEM so let’s load it: data(meadows) First, let’s construct the “free” model in lavaan: jutila_model &lt;- &#39; rich ~ elev + mass mass ~ elev &#39; jutila_lavaan &lt;- sem(jutila_model, meadows, group = &quot;grazed&quot;) ## Warning in lav_data_full(data = data, group = group, cluster = cluster, : ## lavaan WARNING: some observed variances are (at least) a factor 1000 times ## larger than others; use varTable(fit) to investigate summary(jutila_lavaan) ## lavaan 0.6-2 ended normally after 53 iterations ## ## Optimization method NLMINB ## Number of free parameters 14 ## ## Number of observations per group ## 1 165 ## 0 189 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 0 ## ## Chi-square for each group: ## ## 1 0.000 ## 0 0.000 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## ## Group 1 [1]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## rich ~ ## elev 0.073 0.010 7.232 0.000 ## mass -0.001 0.002 -0.424 0.672 ## mass ~ ## elev -1.203 0.470 -2.559 0.010 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich 7.169 0.708 10.126 0.000 ## .mass 260.855 26.764 9.746 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich 12.459 1.372 9.083 0.000 ## .mass 28057.590 3089.039 9.083 0.000 ## ## ## Group 2 [0]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## rich ~ ## elev 0.088 0.011 7.988 0.000 ## mass -0.007 0.001 -5.465 0.000 ## mass ~ ## elev -3.274 0.554 -5.908 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich 11.349 0.750 15.139 0.000 ## .mass 451.732 24.949 18.107 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich 14.384 1.480 9.721 0.000 ## .mass 43567.994 4481.792 9.721 0.000 In this example, the model fit can’t be determined because the model is saturated (df = 0). This is key moving forward because constraining paths will free up degrees of freedom with which to evaluate model fit. Let’s begin by constraining all paths: jutila_lavaan2 &lt;- sem(jutila_model, meadows, group = &quot;grazed&quot;, group.equal = c(&quot;intercepts&quot;, &quot;regressions&quot;)) ## Warning in lav_data_full(data = data, group = group, cluster = cluster, : ## lavaan WARNING: some observed variances are (at least) a factor 1000 times ## larger than others; use varTable(fit) to investigate summary(jutila_lavaan2) ## lavaan 0.6-2 ended normally after 44 iterations ## ## Optimization method NLMINB ## Number of free parameters 14 ## Number of equality constraints 5 ## ## Number of observations per group ## 1 165 ## 0 189 ## ## Estimator ML ## Model Fit Test Statistic 98.261 ## Degrees of freedom 5 ## P-value (Chi-square) 0.000 ## ## Chi-square for each group: ## ## 1 41.124 ## 0 57.136 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## ## Group 1 [1]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## rich ~ ## elev (.p1.) 0.072 0.008 9.077 0.000 ## mass (.p2.) -0.003 0.001 -2.629 0.009 ## mass ~ ## elev (.p3.) -2.527 0.364 -6.934 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich (.p7.) 8.965 0.556 16.119 0.000 ## .mass (.p8.) 369.141 19.001 19.427 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich 14.372 1.582 9.083 0.000 ## .mass 31207.882 ## ## ## Group 2 [0]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## rich ~ ## elev (.p1.) 0.072 0.008 9.077 0.000 ## mass (.p2.) -0.003 0.001 -2.629 0.009 ## mass ~ ## elev (.p3.) -2.527 0.364 -6.934 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich (.p7.) 8.965 0.556 16.119 0.000 ## .mass (.p8.) 369.141 19.001 19.427 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich 17.997 1.851 9.721 0.000 ## .mass 47113.409 anova(jutila_lavaan2) ## Chi Square Test Statistic (unscaled) ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## Saturated 0 0.000 ## Model 5 6754.4 6789.2 98.261 98.261 5 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The model is significantly different from the unconstrained model we fit previously, implying that some paths could be constrained. Moreover, by constraining the coefficients, we now have 5 degrees of freedom to evaluate model fit. However, it is a poor fit, implying that some path coefficients must vary among groups. The next step is to sequentially relax and constrain paths: jutila_model2 &lt;- &#39; rich ~ elev + mass mass ~ c(&quot;b1&quot;, &quot;b1&quot;) * elev &#39; jutila_lavaan3 &lt;- sem(jutila_model2, meadows, group = &quot;grazed&quot;) ## Warning in lav_data_full(data = data, group = group, cluster = cluster, : ## lavaan WARNING: some observed variances are (at least) a factor 1000 times ## larger than others; use varTable(fit) to investigate ## Warning in lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats, : lavaan WARNING: ## The variance-covariance matrix of the estimated parameters (vcov) ## does not appear to be positive definite! The smallest eigenvalue ## (= 4.499242e-21) is close to zero. This may be a symptom that the ## model is not identified. anova(jutila_lavaan, jutila_lavaan3) ## Chi Square Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## jutila_lavaan 0 6666.2 6720.3 0.0000 ## jutila_lavaan3 1 6672.2 6722.5 8.0301 8.0301 1 0.004601 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 The model is still a poor fit, and it is significantly different from the “free” model. In this case, we would conclude that the \\(elev -&gt; mass\\) path should not be constrained. Let’s repeat for the next two paths: # elev -&gt; rich jutila_model3 &lt;- &#39; rich ~ c(&quot;b2&quot;, &quot;b2&quot;) * elev + mass mass ~ elev &#39; jutila_lavaan4 &lt;- sem(jutila_model3, meadows, group = &quot;grazed&quot;) ## Warning in lav_data_full(data = data, group = group, cluster = cluster, : ## lavaan WARNING: some observed variances are (at least) a factor 1000 times ## larger than others; use varTable(fit) to investigate ## Warning in lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats, : lavaan WARNING: ## The variance-covariance matrix of the estimated parameters (vcov) ## does not appear to be positive definite! The smallest eigenvalue ## (= -3.785594e-18) is smaller than zero. This may be a symptom that ## the model is not identified. anova(jutila_lavaan, jutila_lavaan4) ## Chi Square Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## jutila_lavaan 0 6666.2 6720.3 0.0000 ## jutila_lavaan4 1 6665.1 6715.4 0.9477 0.94767 1 0.3303 # mass -&gt; rich jutila_model4 &lt;- &#39; rich ~ elev + c(&quot;b3&quot;, &quot;b3&quot;) * mass mass ~ elev &#39; jutila_lavaan5 &lt;- sem(jutila_model4, meadows, group = &quot;grazed&quot;) ## Warning in lav_data_full(data = data, group = group, cluster = cluster, : ## lavaan WARNING: some observed variances are (at least) a factor 1000 times ## larger than others; use varTable(fit) to investigate ## Warning in lav_model_vcov(lavmodel = lavmodel, lavsamplestats = lavsamplestats, : lavaan WARNING: ## The variance-covariance matrix of the estimated parameters (vcov) ## does not appear to be positive definite! The smallest eigenvalue ## (= 3.376474e-14) is close to zero. This may be a symptom that the ## model is not identified. anova(jutila_lavaan, jutila_lavaan5) ## Chi Square Difference Test ## ## Df AIC BIC Chisq Chisq diff Df diff Pr(&gt;Chisq) ## jutila_lavaan 0 6666.2 6720.3 0.0000 ## jutila_lavaan5 1 6673.6 6723.9 9.4642 9.4642 1 0.002095 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Of these two paths, it seems the first: \\(elev -&gt; rich\\), is not significantly different from the “free” model, implying that this path could be constrained. Oppositely, it seems the significant difference between the “free” model and one in which the \\(mass -&gt; rich\\) path is constrained is not supported Let’s check the fit of the model with the one constrait on \\(elev -&gt; rich\\): summary(jutila_lavaan4) ## lavaan 0.6-2 ended normally after 53 iterations ## ## Optimization method NLMINB ## Number of free parameters 14 ## Number of equality constraints 1 ## ## Number of observations per group ## 1 165 ## 0 189 ## ## Estimator ML ## Model Fit Test Statistic 0.948 ## Degrees of freedom 1 ## P-value (Chi-square) 0.330 ## ## Chi-square for each group: ## ## 1 0.435 ## 0 0.513 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## ## Group 1 [1]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## rich ~ ## elev (b2) 0.080 0.007 10.717 0.000 ## mass -0.000 0.002 -0.297 0.767 ## mass ~ ## elev -1.203 0.470 -2.559 0.010 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich 6.795 0.596 11.408 0.000 ## .mass 260.855 26.764 9.746 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich 12.492 1.375 9.083 0.000 ## .mass 28057.590 NA ## ## ## Group 2 [0]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## rich ~ ## elev (b2) 0.080 0.007 10.717 0.000 ## mass -0.008 0.001 -5.999 0.000 ## mass ~ ## elev -3.274 0.554 -5.908 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich 11.754 0.624 18.831 0.000 ## .mass 451.732 24.949 18.107 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .rich 14.423 1.484 9.721 0.000 ## .mass 43567.993 NA Now the model fits the data well (\\(P = 0.330\\)), and we have, through an iterative procedure of imposing and relaxing constraints, determined which paths differ among groups (\\(elev -&gt; mass\\), \\(mass -&gt; rich\\)) and which do not (\\(elev -&gt; rich\\)). Now let’s confirm this by fitting the model in piecewiseSEM: jutila_psem &lt;- psem( lm(rich ~ elev + mass, meadows), lm(mass ~ elev, meadows) ) multigroup(jutila_psem, group = &quot;grazed&quot;) ## ## Structural Equation Model of jutila_psem ## ## Groups = grazed [ 1, 0 ] ## ## --- ## ## Global goodness-of-fit: ## ## Fisher&#39;s C = 0 with P-value = 1 and on 0 degrees of freedom ## ## --- ## ## Model-wide Interactions: ## ## Response Predictor Test.Stat DF P.Value ## rich elev:grazed 12.7 1 0.3358 ## rich mass:grazed 126.3 1 0.0026 ** ## mass elev:grazed 287418.5 1 0.0055 ** ## ## elev -&gt; rich constrained to the global model ## ## --- ## ## Group [1] coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## rich elev 0.0731 0.0081 351 8.9882 0.0000 0.4967 ## rich mass -0.0007 0.0017 162 -0.4198 0.6752 -0.0291 ## mass elev -1.2028 0.4728 163 -2.5438 0.0119 -0.1954 ## ## c *** ## ## * ## ## Group [0] coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## rich elev 0.0731 0.0081 351 8.9882 0 0.3933 ## rich mass -0.0072 0.0013 186 -5.4216 0 -0.3222 ## mass elev -3.2735 0.5571 187 -5.8764 0 -0.3948 ## ## c *** ## *** ## *** ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 c = constrained As in our analysis in lavaan, the multigroup function has identified the \\(elev -&gt; rich\\) path as the only one in which coefficients do not differ among groups. Thus, in the output, that coefficient is the same between groups; otherwise, the coefficients vary depending on whether the meadows is grazed or ungrazed. Moreover, it seems some of the paths differ in their statistical significance: the \\(rich -&gt; mass\\) is not significant in the grazed meadows, but is significant in the ungrazed meadows. So not only do the coefficients differ, but the model structure as well! You’ll note that the piecewiseSEM output does not return a goodness-of-fit test because the model is saturated (i.e., no missing paths). While constraints are incorporated in terms of offsets (i.e., fixing model coefficients), unlike global estimation, this does not provide new information with which to test goodness-of-fit. This is a limitation of local estimation that extends beyond multigroup modeling to any piecewise model. To draw inference about the study system, we would say that two paths differ among groups and one path does not. We would then report the two path models parameterized using the coefficient output (with the \\(elev -&gt; rich\\) path having the same coefficient in both groups). We would report that richness is affected by elevation and biomass under ungrazed conditions, but not under grazed conditions, where only elevation directly influences richness. 5.5 References Grace, J. B., &amp; Jutila, H. (1999). The relationship between species density and community biomass in grazed and ungrazed coastal meadows. Oikos, 398-408. "],
["latent-variable-modeling.html", "6 Latent Variable Modeling 6.1 Introduction to Latent Variable Modeling 6.2 Application of Latent Variables to Path Models 6.3 Latent Variables in lavaan 6.4 Multi-indicator Latent Variables 6.5 Confirmatory Factor Analysis 6.6 Travis &amp; Grace (2010): An Example 6.7 References", " 6 Latent Variable Modeling 6.1 Introduction to Latent Variable Modeling Latent variables are variables that are unobserved, but whose influence can be summarized through one or more indicator variables. They are useful for capturing complex or conceptual properties of a system that are difficult to quantify or measure directly. Early applications of latent variables, for example, focused on modeling the effects of ‘general intelligence,’ which is an abstract concept that is impossible to actually measure, but can be approximated using scores from different tests of cognitive performance (e.g., memory, verbal, spatial, etc.). Consider the following simple example of a latent variable, in this case exogenous (informed only by a single predictor): latent variable Here, the latent variable is indicated by the circle marked by \\(\\xi\\). The single indicator variable \\(x\\) is indicated by the square box, as are all observed variables. You’ll note a few curiosities compared to observed-variable models. First, the direction of causality is reversed from what you might expect: from the latent variables to the observed variable. This is because the indicator variable is simply an emergent manifestion of the underlying phenomenon represented by the latent variable. Second, there is an error \\(\\delta\\) associated with the indicator. This implies that the indicator is often an imperfect approximation of the latent construct. In other words, there are other factors influencing the correlation between the observed and latent variable. The latent variable can be related to the indicator variable using the following equation: \\[x = \\lambda \\xi + \\delta_{x}\\] Here, the values of \\(x\\) are the result of the latent variable proportional to \\(\\lambda\\) (its effect on \\(x\\)) plus some error \\(\\delta_{x}\\). A simple example of a latent-indicator relationship would be body size (latent) and body mass (indicator). There are obviously many aspects to body size that may be difficult to quantify, such as shape, volume, complexity, and so on. However, body mass is a simple, measurable consequence of these unmeasured characteristics, and thus can be thought to latently indicate body size. However, because we often can’t perfectly measure body mass of every individual we are interested in, we must incorporate sampling error into our model of body size. This example reinforces the point that latent variables are used to represent concepts. Body size is often invoked in lots of ecological hypotheses (e.g., metabolic theory, Bergmann’s rule), but is almost always represented as some easily measurable quantity such as body mass rather than the complex, multidimensional construct that it is in reality. Latent variable modeling allows us to better approach that multidimensional construct by modeling a series of indicator variables that arise from the general concept of body size (e.g., mass, length, width, etc.). It therefore is a powerful tool that is better positioned to integrate theory and observation than relying on one or few surrogates. However, some care should be taken when constructing latent variables. Just because we call a latent variable something does not always mean it is that thing. For example, the latent variable body size as indicated by total abundance might appear legitimate–high abundances may constrain body sizes under limited resources–but is abundance really an indicator of this phenomenon? Can we go on to evaluate ecological theory about metabolic scaling on the basis of abundances? Probably not. So care should be taken when selecting/naming latent variables and identifying appropriate indicators (known as the naming fallacy). In other words: be sure the latent variable reflects the actual properties captured by the indicator variables! The degree to which the indicators represent the phenomenon captured by the latent variable is termed validity and is a qualitative justification of the latent construct. In contrast, reliability of the latent variable provides quantitative values with which to gauge how well an indicator reflects the latent variable. Reliability implies that the same values of the indicator would be obtained if they were continually resampled again and again. In other words, reliable indicators approach the true population mean that is the (theoretical) product of the latent variable: a perfect indicator would generate the same values every time so they would have a correlation \\(r = 1\\). Of course, rarely do we sample an entire population or so well, and there will inevitably be some differences among our samples leading to deviations in \\(r\\) away from 1. From this correlation, we can obtain a path coefficient from the latent to the indicator variable. Recall from the “Rules of Path Coefficients” (see Chapter: Global Estimation) the the coefficient on the path from the error variance \\(\\zeta\\) is the square-root of the unexplained variance (Rule 5). In this case, we want the opposite: we want the shared variance between the latent and indicator variable (a lot of shared variance is what makes a good indicator!). As in the case of the error path, the path coefficient from the latent variable to the indicator is often expressed in its standardized form: the square-root of the reliability. This value is also known as the loading. From the reliability, we can also obtain the standardized error term \\(\\delta_{x}\\). This is the unshared variance, or 1 - the reliability. For the unstandardized form, one can apply the following equation: \\[\\delta_{x} = (1 - \\lambda_{x}^2) \\times VAR_{x}\\] As with other coefficients, standardization is applied simply because multiple indicators may be measured in vastly different units, and one may wish to fairly compare the loadings and errors. Let’s construct a simple example. Say we sample the variable \\(x\\) repeatedly 5 times with \\(n = 10\\). This could be 5 sampling dates or 5 separate trials. set.seed(11) x &lt;- rnorm(10) x.list &lt;- lapply(1:5, function(i) x + runif(10, 0, 2)) x. &lt;- unlist(x.list) We can compute the average correlation among all trials. This is our measure of reliability: combos &lt;- combn(1:5, 2) cors &lt;- c() for(i in 1:ncol(combos)) cors &lt;- c(cors, cor(x.list[[combos[1, i]]], x.list[[combos[2, i]]])) (r &lt;- mean(cors)) ## [1] 0.804403 From this value \\(r = 0.804\\), we can obtain the path coefficient and the (standardized error variance): sqrt(r) # path coefficient ## [1] 0.8968852 1 - r # standardized error variance ## [1] 0.195597 (1 - r) * var(unlist(x.list)) # unstandardized error variance ## [1] 0.213149 In summary: the standardized coefficient (the loading) linking indicator to latent variables is the square-root of the relability. The standardized error variance is 1 - reliability. So far, we have only dealt with latent variables as exogenous (predictor) variables, but they can also act as endogenous (response) variables. Here is an example endogenous latent variable: latent variable The graph looks roughly similar, with some changes in the parameters: the error variance on \\(y\\) is now \\(\\epsilon_{y}\\), while the latent variable itself is represented as \\(\\eta\\) and it has its own error \\(\\zeta\\). The presence of this additional error presents a challenge: we simply don’t have enough information to estimate all the unknowns here. In this case, we assume no measurement error on \\(y\\) such that \\(\\epsilon_{y} = 0\\). Consequently, \\(y\\) becomes a perfect indicator of \\(\\eta\\) such that the reliability is total and \\(\\lambda_{y} = 1\\). We will get the calculation of \\(\\zeta\\) momentarily, which involves the value of the path(s) leading into \\(\\eta\\). 6.2 Application of Latent Variables to Path Models Allowing both exogenous and endogenous latent variables now allows us to fit a structural model, or one with directed paths between latent variables. This is in contrast to a measurement model, which focuses solely on relating indicators to latent variables. As an example of a structural model, let’s combine the two latent variable models so that the exogenous latent variable is predicting the endogenous one: latent structural model As before, let’s fix the error of \\(y\\) to be 0 so that the loading on \\(\\eta = 1\\). We can solve the exogenous paths as before, leaving us with two parameters left: the path coefficient \\(\\gamma\\) and \\(\\zeta\\). We can solve the path coefficient \\(\\gamma\\) by knowing the regression coefficient (correlation) between the raw values of \\(x\\) and \\(y\\) and adjusting by the loading of \\(x\\) on \\(\\xi\\). Let’s return to our previous example and generate some data for \\(y\\), then estimate the (standardized) coefficient, or correlation: set.seed(3) y &lt;- x + runif(10, 0, 5) y.list &lt;- lapply(1:5, function(i) y + runif(10, 0, 2)) y. &lt;- unlist(y.list) xy_model &lt;- lm(y. ~ x.) beta &lt;- summary(xy_model)$coefficients[2, 1] (beta_std &lt;- beta * (sd(x.) / sd(y.))) # standardized ## [1] 0.5440115 cor(x., y.) # same as the standardized coefficient for simple regression ## [1] 0.5440115 In this example, the estimated standardized path coefficient for \\(x\\) on \\(y\\) is \\(b = 0.544\\). We can obtain an estimate of gamma using the following equation: \\[\\gamma = \\frac{b}{\\lambda}\\] Which, for our example, is: (gamma &lt;- beta_std / sqrt(r)) ## [1] 0.6065565 So the new estimate of the coefficient between the two latent variables is \\(\\gamma = 0.607\\). This is because the measurement error in \\(x\\) was formerly lumped in to the prediction error of \\(y\\): by removing it, we have improved the estimate of the true effect of \\(x\\) on \\(y\\). Not accounting for measurement error, then, results in a downward bias in both the coefficients and the variance explained. From this value, we can obtain the unexplained variance, or \\(\\zeta\\). Recall that the error \\(\\delta_{x}\\) is 1 - the explained variance, where the explained variance is the reliability. Here, we can transfer this knowledge such that: \\(\\zeta = 1 - \\gamma^2\\): 1 - gamma^2 ## [1] 0.6320892 # compare to regression residual variance 1 - summary(xy_model)$r.squared ## [1] 0.7040515 The error variance has decreased from 0.704 to 0.632 relative to the linear model, again, as a consequence of removing the measurement error in \\(x\\). So, by incorporating the error in \\(x\\) into our model, we have improved our estimate of the relationship between \\(x\\) and \\(y\\) and decreased the unexplained variance. 6.3 Latent Variables in lavaan Let’s reproduce this example using lavaan. The setup is almost identical except for a new operator =~ which indicates a latent variable. Additionally, we will fix the error variance in \\(x\\) to the known (unstandardized) error variance from our repeated trials. library(lavaan) ## This is lavaan 0.6-2 ## lavaan is BETA software! Please report any bugs. (1 - r) * var(x.) # unstandardized error variance ## [1] 0.213149 latent_formula1 &lt;- &#39; xi =~ x # exogenous latent eta =~ y # endogenous latent eta ~ xi # path model x ~~ 0.213 * x # fix error variance &#39; latent_model1 &lt;- sem(latent_formula1, data.frame(x = x., y = y.)) summary(latent_model1, standardize = T, rsq = T) ## lavaan 0.6-2 ended normally after 22 iterations ## ## Optimization method NLMINB ## Number of free parameters 3 ## ## Number of observations 50 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 0 ## Minimum Function Value 0.0000000000000 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## xi =~ ## x 1.000 0.925 0.895 ## eta =~ ## y 1.000 1.504 1.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## eta ~ ## xi 0.989 0.221 4.469 0.000 0.608 0.608 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .x 0.213 0.213 0.199 ## .y 0.000 0.000 0.000 ## xi 0.855 0.214 4.003 0.000 1.000 1.000 ## .eta 1.426 0.327 4.363 0.000 0.630 0.630 ## ## R-Square: ## Estimate ## x 0.801 ## y 1.000 ## eta 0.370 If we examine the output, we find a poor-fitting model, but let’s ignore that for now considering these were just random data. Instead, let’s focus on the estimated parameters and compare them to our hand-calculated values. The standardized loading on \\(xi = 0.895\\) which is very close to the value we calculated \\(\\sqrt(r) = 0.897\\). The loading on \\(\\eta\\) is \\(\\lambda_{y} = 1\\). Notice how we didn’t specify that: the default in lavaan is to set the first loading to 1 when the error variance is not supplied (more on this later). With respect to the regression coefficient, lavaan returned a standardized \\(\\gamma = 0.608\\) while we obtained \\(\\gamma = 0.607\\). Very close! Similarly the standardized error variance on \\(\\eta\\) is \\(\\zeta = 0.630\\), which is also very close to \\(1 - \\gamma^2 = 0.632\\). Naturally, then, the explained variances are also nearly identical, being 1 - error variance. So, all in all, for single indicator latent variables, we are able to almost exactly reproduce the output from lavaan (slight differences are due to the optimization algorithm). One could alternately fix the error of the exogenous latent variable and incorporate measurement error of \\(y\\): cors.y &lt;- c() for(i in 1:ncol(combos)) cors.y &lt;- c(cors.y, cor(y.list[[combos[1, i]]], y.list[[combos[2, i]]])) (r.y &lt;- mean(cors.y)) ## [1] 0.8535083 (1 - r.y) * var(y.) # unstandardized error variance ## [1] 0.3380926 latent_formula2 &lt;- &#39; xi =~ x # exogenous latent eta =~ y # endogenous latent eta ~ xi # path model y ~~ 0.338 * y # fix error variance &#39; latent_model2 &lt;- sem(latent_formula2, data.frame(x = x., y = y.)) summary(latent_model2, standardize = T, rsq = T) ## lavaan 0.6-2 ended normally after 11 iterations ## ## Optimization method NLMINB ## Number of free parameters 3 ## ## Number of observations 50 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 0 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## xi =~ ## x 1.000 1.033 1.000 ## eta =~ ## y 1.000 1.387 0.922 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## eta ~ ## xi 0.792 0.173 4.584 0.000 0.590 0.590 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .y 0.338 0.338 0.149 ## .x 0.000 0.000 0.000 ## xi 1.068 0.214 5.000 0.000 1.000 1.000 ## .eta 1.254 0.318 3.939 0.000 0.652 0.652 ## ## R-Square: ## Estimate ## y 0.851 ## x 1.000 ## eta 0.348 Here, because we did not specify it, the error variance of \\(x\\) has automatically been fixed to 0 and the loading to 1. To start, the standardized \\(\\gamma = 0.590\\), which is lower than the \\(\\gamma = 0.608\\) we obtained when incorporating measurement error on \\(x\\), but higher than the standardized coefficient from a simple linear regression \\(b = 0.544\\). The error variance on \\(\\eta\\) (\\(\\zeta = 0.652\\)) is also lower than the unexplained variance from the linear regression (\\(1 - R^2 = 0.704\\)), but higher than in the latent variable model incorpoting error on \\(x\\) (\\(\\zeta = 0.630\\)). The unstandardized coefficient, however, is unchanged: \\(\\beta = 0.792\\). This is in contrast to the earlier latent variable model, where the unstandardized estimate was 0.989. Thus, we see that incorporating measurement error in endogenous latent variables resolves some of the downward bias in the unstandardized coefficient and error variance, but not the unstandardized coefficient. This difference emphasizes the need to report both standardized and unstandardized coefficients when constructing a path model (see Chapter: Coefficients). For the moment, latent variables are restricted to covariance-based SEM, although we are working to extend some concepts using the piecewise framework. lavaan, however, provides an easier, robust framework that easily extends to multi-indicator latent variables, and so we will use it from here on out. 6.4 Multi-indicator Latent Variables Accounting for measurement error requires some estimate of reliability. Often, we don’t have a measure of reliability, because we don’t design our experiments to obtain one. In such cases, it might be recommended to revert to a non-latent variable approach where the path coefficients are not informed by any loadings. Another solution is to incorporate multiple indicator variables to provide a different measure of reliability. In this case, the correlation is not derived from multiple samples of the same indicator, but among indicators. It also acts as a check against indicators that do not inform the latent variable, as such variables will provide low reliability estimates. This approach also provides a conceptual advantage: we often choose a single indicator as a surrogate for a latent concept (e.g., body mass for body size). Including more indicators helps to generalize this phenomenon by testing that the result is not an impact of the choice of any single indicator. Multiple indicators raises a new problem, though: identifiability. Remember from the chapter on Global Estimation that we must have enough known pieces of information to estimate all the unknown quantities implied by the model. Latent variable models must also follow the “t-rule” (see Chapter: Global Estimation). Consider an exogenous latent variable indicated by two variables, \\(x1\\) and \\(x1\\). We can break this latent variable into two equations: \\[x1 = \\lambda_{1}\\xi + \\delta_{x1}\\] \\[x2 = \\lambda_{2}\\xi + \\delta_{x1}\\] We know the values of \\(x1\\) and \\(x2\\) and only know the correlation between them. To estimate values for the latent construct \\(\\xi\\) we need to estimate \\(lambda_{1}\\), \\(\\lambda_{2}\\), \\(\\delta_{x1}\\) and \\(\\delta_{x2}\\). This model fails the t-rule, which, if you recall, is: \\[t \\leq \\frac{n(n+1)}{2}\\] where \\(t = 4\\) is the number of unknowns, and \\(n = 2\\) is the number of knowns. In this example, \\(t = 4 \\leq 3\\) does not hold. Since \\(\\delta = 1 - \\lambda^2\\), we need only solve for the two \\(\\lambda\\)s, but we only have 1 piece of information: the correlation. The solution is to set the loadings to be equal: \\(lambda_{1} = \\lambda_{2}\\). This is because, with only this information, we have no reason to suspect one indicator is more correlated with the latent variable than the other. Its important to note here that the two must be positively correlated (or scaled to be so), otherwise setting them to be equal is not a valid assumption. We know from our “Rules of Path Coefficients” that the correlation equals the sum of the direct and indirect pathways (Rule 9). The only path connecting \\(x1\\) and \\(x2\\) is through \\(\\epsilon\\), and the value of the compound path is the product of the two individual pathways (Rule 3). Thus, the correlation \\(r_{x1,x2} = lambda_{1} \\times \\lambda_{2}\\). Given the assumption that the two loadings are equal, \\(r_{x1,x2} = \\lambda^2\\) and thus \\(\\lambda = \\sqrt(r_{x1,x2})\\). We can scale this procedure for &gt;2 indicators by setting just the 2 loadings to be equal: this will give us the necessary information (along with Rule 8 of path coefficients) to generate unique solutions for the other loadings. It is for this reason that at least three indicators are preferred for multi-indicator latent variables: it lessens the impact of the assumption that two loadings are equal. An better solution is to fix one of the loadings to be 1. If, for example, we fix \\(\\lambda_{1} = 1\\) then we know that \\(\\lambda_{2} = r_{x1,x2} / \\lambda_{1} = r_{x1,x2} / 1 = r_{x1,x2}\\). This choice has another consequence: because it is unmeasured, we also need to provide a scale for our multi-indicator latent variable. This can be done by fixing the variance \\(\\zeta = 1\\) or by fixing one of the unstandardized loadings to 1. Both accomplish the same objective. Finally, we can obtain an integrated estimate of reliability from multi-indicator latent variables using the following equation: \\[\\rho_{xi,xj} = \\frac{(\\sum\\lambda_{j})^2}{(\\sum\\lambda_{j})^2 + \\sum\\epsilon_{j}} \\] where \\(j\\) is the number of indicator variables. For the record, a reliability index &gt; 0.9 is considered ‘excellent’, &gt; 0.8 to be ‘good’, and so on. Anything &lt; 0.5 is considered to be no different than random chance, and so indicators with such a low degree of correlation should be avoided. In fact, it is always recommended to inspect the correlation matrix among indicator variables to screen for potentially unrelated indicators. It may also help to identify indicators that are highly correlated, moreso than the other indicators. Such high correlations might suggest another common cause (such as the same measurement instrument, same observer, evolutionary constraints, etc.). In this case, it would be recommended to indicate a ‘correlated error’ among the two indicators indicating an underlying driver of their higher-than-average association beyond that imparted by the latent construct. When we get into the realm of multi-indicator latent variables, it becomes impossible to decompose partial relationships as we have previously for observed variable models (see Chapter: Global Estimation). Instead, maximum-likelihood functions are necessary to iteratively test and optimize the parameters that describe the relationships between observed and unobserved quantities. As in observed-variable models, maximum-likelihood estimators (\\(F_{ML}\\)) can be used to construct a \\(\\chi^2\\) statistic that is the difference between the observed and model-implied variance-covariance matrices (see Chapter: Global Estimation). In the case of latent variable models, the covariances among latent variables as well as the loadings are considered in constructing the estimated covariance matrix. Beyond that, the procedure is the same as for observed variable models in terms of calculating \\(\\chi^2\\) and testing it against the \\(\\chi^2\\)-distribution with some model degrees of freedom. 6.5 Confirmatory Factor Analysis Multi-indicator latent variables can also be used to the test the hypothesis that a suite of indicator variables are generated by the same underlying process. This is also called confirmatory factor analysis. In other words, you are testing the idea that the latent variable has given rise to emergent properties that, by virtue of a common cause, are correlated. This approach concerns only the measurement model and thus is a precursor to evaluation of any structural models in which the latent variables appear. In contrast, exploratory factor analysis assumes that all latent variables are indicated by all observed variables. [content pending] 6.6 Travis &amp; Grace (2010): An Example Let’s apply these concepts to an example dataset from Travis &amp; Grace (2010). In this example, the authors transplanted individuals of the salt marsh plant Spartina alterniflora and measured their performance relative to local populations. In this case, performance was captured by a number of variables including: stem density, the number of infloresences, clone diameter, leaf height, and leaf width. The difference between transplants and local individuals was quantified using their genetic dissimilarity. In this case, the authors considered ‘performance’ to be a latent construct that manifests in the five indicators listed above: travis latent Let’s first explore this latent construct before getting into the structural model. First, let’s examine the raw correlations to see if this construct is justifiable: travis &lt;- read.csv(&quot;./data/travis.csv&quot;) cor(travis[, 4:8]) ## stems infls clonediam leafht leafwdth ## stems 1.0000000 0.8339227 0.9333150 0.7275625 0.6457378 ## infls 0.8339227 1.0000000 0.8126388 0.6925888 0.6026302 ## clonediam 0.9333150 0.8126388 1.0000000 0.7729843 0.7296621 ## leafht 0.7275625 0.6925888 0.7729843 1.0000000 0.9687725 ## leafwdth 0.6457378 0.6026302 0.7296621 0.9687725 1.0000000 The correlations range from 0.65-0.93, suggesting that these variables may be generated by the same process. There is one excessive correlation between leaf height and width, potentially suggesting influence by another process. Now that we have qualitatively assessed the validity of the latent model, let’s fit it and examine the output: travis_latent_formula1 &lt;- &#39;performance =~ stems + infls + clonediam + leafht + leafwdth&#39; travis_latent_model1 &lt;- sem(travis_latent_formula1, travis) ## Warning in lav_object_post_check(object): lavaan WARNING: some estimated ov ## variances are negative summary(travis_latent_model1) ## lavaan 0.6-2 ended normally after 82 iterations ## ## Optimization method NLMINB ## Number of free parameters 10 ## ## Number of observations 23 ## ## Estimator ML ## Model Fit Test Statistic 51.106 ## Degrees of freedom 5 ## P-value (Chi-square) 0.000 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## performance =~ ## stems 1.000 ## infls 0.126 0.037 3.377 0.001 ## clonediam 1.160 0.309 3.751 0.000 ## leafht 1.215 0.244 4.971 0.000 ## leafwdth 0.151 0.031 4.822 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .stems 125.886 37.014 3.401 0.001 ## .infls 2.405 0.707 3.403 0.001 ## .clonediam 132.478 39.038 3.394 0.001 ## .leafht -1.847 5.336 -0.346 0.729 ## .leafwdth 0.223 0.105 2.131 0.033 ## performance 135.763 67.580 2.009 0.045 Note that the first loading has been restricted to 1 for purposes of identifiability. First, we note that the model is a poor fit (\\(P &lt; 0.001\\)). We can explore why this is using modification indices: print(modindices(travis_latent_model1)) ## lhs op rhs mi epc sepc.lv sepc.all sepc.nox ## 12 stems ~~ infls 10.470 11.784 11.784 0.677 0.677 ## 13 stems ~~ clonediam 17.152 112.521 112.521 0.871 0.871 ## 14 stems ~~ leafht 0.693 -7.889 -7.889 -0.517 -0.517 ## 15 stems ~~ leafwdth 2.214 -1.836 -1.836 -0.346 -0.346 ## 16 infls ~~ clonediam 8.773 11.092 11.092 0.621 0.621 ## 17 infls ~~ leafht 0.062 -0.312 -0.312 -0.148 -0.148 ## 18 infls ~~ leafwdth 2.906 -0.281 -0.281 -0.383 -0.383 ## 19 clonediam ~~ leafht 4.028 -21.233 -21.233 -1.357 -1.357 ## 20 clonediam ~~ leafwdth 0.037 -0.261 -0.261 -0.048 -0.048 ## 21 leafht ~~ leafwdth 37.862 17.177 17.177 26.752 26.752 Recall that the value of the modification index (mi in the output) is the expected decrease in the model \\(\\chi^2\\). Here, a larger number would imply a better fit. It seems there is a strong implied correlation between leaf height and leaf width, presumably arising from common constraints on how the leaves of Spartina have evolved and the limited variety of shapes they can take, and not the plant’s performance. We can introduce this correlation into the model and re-fit: travis_latent_formula2 &lt;- &#39; performance =~ stems + infls + clonediam + leafht + leafwdth leafht ~~ leafwdth &#39; travis_latent_model2 &lt;- sem(travis_latent_formula2, travis) summary(travis_latent_model2) ## lavaan 0.6-2 ended normally after 81 iterations ## ## Optimization method NLMINB ## Number of free parameters 11 ## ## Number of observations 23 ## ## Estimator ML ## Model Fit Test Statistic 7.410 ## Degrees of freedom 4 ## P-value (Chi-square) 0.116 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## performance =~ ## stems 1.000 ## infls 0.117 0.016 7.173 0.000 ## clonediam 1.086 0.096 11.319 0.000 ## leafht 0.697 0.127 5.509 0.000 ## leafwdth 0.082 0.018 4.529 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .leafht ~~ ## .leafwdth 10.831 3.432 3.156 0.002 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .stems 15.267 10.877 1.404 0.160 ## .infls 1.204 0.390 3.085 0.002 ## .clonediam 24.786 13.830 1.792 0.073 ## .leafht 78.958 24.465 3.227 0.001 ## .leafwdth 1.672 0.509 3.283 0.001 ## performance 246.382 77.658 3.173 0.002 Introducing this correlated error has now reduced the \\(\\chi^2\\) statistic to an acceptably low level (\\(P = 0.116\\)). Thus, we have arrived at a legitimate latent construct of plant performance, which we can now use to evaluate some broader hypotheses. If you recall, the authors’ original intent was to explore how native vs. non-native genotypes of Spartina influenced performance, which they quantified using a measure of genetic distance from the local population. To test this hypothesis, let’s fit the following path model: travis path model Let’s fit the above model: travis_path_formula1 &lt;- &#39; # latent performance =~ stems + infls + clonediam + leafht + leafwdth # structural paths performance ~ geneticdist # correlated errors leafht ~~ leafwdth &#39; travis_path_model1 &lt;- sem(travis_path_formula1, travis) summary(travis_path_model1) ## lavaan 0.6-2 ended normally after 107 iterations ## ## Optimization method NLMINB ## Number of free parameters 12 ## ## Number of observations 23 ## ## Estimator ML ## Model Fit Test Statistic 12.237 ## Degrees of freedom 8 ## P-value (Chi-square) 0.141 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Latent Variables: ## Estimate Std.Err z-value P(&gt;|z|) ## performance =~ ## stems 1.000 ## infls 0.117 0.017 6.929 0.000 ## clonediam 1.106 0.096 11.508 0.000 ## leafht 0.711 0.127 5.601 0.000 ## leafwdth 0.084 0.018 4.650 0.000 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## performance ~ ## geneticdist -51.673 11.365 -4.547 0.000 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) ## .leafht ~~ ## .leafwdth 10.416 3.312 3.145 0.002 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .stems 19.691 10.733 1.835 0.067 ## .infls 1.246 0.401 3.108 0.002 ## .clonediam 19.411 12.364 1.570 0.116 ## .leafht 76.177 23.645 3.222 0.001 ## .leafwdth 1.612 0.492 3.278 0.001 ## .performance 120.509 39.656 3.039 0.002 It seems that this model fits the data well (\\(P = 0.141\\)) and the relationship of interest, between genetic distance and performance, is highly significant (\\(P &lt; 0.001\\)). In this case, the more unlike the local population the transplants were (greater genetic distance), the worse they performed. 6.7 References Travis, S. E., &amp; Grace, J. B. (2010). Predicting performance for ecological restoration: a case study using Spartina alterniflora. Ecological Applications, 20(1), 192-204. "],
["composite-variables.html", "7 Composite Variables 7.1 What is a Composite Variable? 7.2 Constructing a Composite Variable 7.3 Grace &amp; Keeley Revisited: A Worked Example 7.4 Composites in piecewiseSEM 7.5 References", " 7 Composite Variables 7.1 What is a Composite Variable? Composite variables are another way, besides latent variables, to represent complex concepts in structural equation modeling. The most important distinction between the two is that, while latent variables give rise to measurable manifestations of an unobservable concept, composite variables arise from the combined influence of other variables. Consider the following composite variable \\(\\eta\\): composite variable Here the arrows are leading into, not out of, \\(\\eta\\), indicating that the composite variable is made up of the influences of the three example variables. Note: in this and other presentations, the composite is denoted by a hexagon, but can sometimes be an oval as it can technically be a form of a latent variable. If the composite is entirely made up of the three influences, it can be said to have no error. An example might be the two levels of a treatment (present/absent) that lead into a single composite variable called ‘Treatment.’ In this case, there are no other levels of treatment because you, as the investigator, did not apply any. Thus the composite ‘Treatment’ captures the full universe of treatment possibilities given the data. In other cases, the property might arise from the collective influence of variables but is not without error. For example, the idea of soil condition arises from different aspects of the soil: its pH, moisture, grain size, and so on. However, one might measure only some of these, and thus there remain other factors (nitrogen content) that might contribute to the notion of soil condition. In this case, the composite would have error and is therefore known as a latent composite. The benefit of such an approach is that complicated ideas can be distilled into discrete blocks that are easier to present and discuss. For example, it is easier to talk about the effects of the experimental treatment on soil condition, rather than the effect of treatment 1 on soil moisture, the effect of treatment 1 on soil pH, the effect of treatment 1 on soil grain size, and so on. In this way, the composite harkens back to the early meta-model, or broad conceptual relationships that inform the parameterization of the structural path model. In fact, in populating the meta-model, you may wish to consider those broad concepts as composites when fitting the model, rather than modeling all relationships among all observed variables. Selecting between latent and composite variables comes down to the concept in question, the presumed direction of causality, and the nature of the indicators. For the soil example, consider: is it that there is a common difference among soils driving variation in pH, moisture, etc.? Or is it that pH, moisture, etc. are all independent properties that combine to inform soil condition? If the goal is measure plant growth in potting soils from different manufacturers, then manufacturer might be the common source of variation and a latent variable more appropriate. If the observer is visiting different sites and measuring conditions that describe the soil in each place, then perhaps a composite variable is warranted. Another way of thinking about this is whether the indicators are interchangeable. In other words, does soil pH tell us the same information as soil moisture? If so, then they might be indicators of the same latent phenomenon. If not, and they contain unique information, then they likely combine to form a composite variable. Finally, do the indicators co-vary? If they are under common control of a latent variable, then changing one should alter all the others. If they are relatively independent–for example, one can change grain size without changing nutrient content–then causation likely flows into a composite (rather than out of a latent) variable. Now that we have defined a composite variable, let’s see how to make one. 7.2 Constructing a Composite Variable Compared to latent variables, a composite variable is actually very easy to estimate: it is simply the sum of its indicators, hence the term composite. The way in which the indicators are summed depends on whether they are expected to have the same weight (a fixed composite) or different weights (a statistical composite). The former might be something like species relative abundances. The latter is what we will focus on here. The weights for the composite are easily acquired as they are the values that maximize the explained variance in some response. We have done this before many times using maximum-likelihood fitting. In fact, statistical composites can be boiled down to the coefficients from a multiple regression. The ML fitting function chooses parameter estimates for each predictor that maximize the likelihood of obseving the response. Those values serve as the loadings for the indicators of the composite variable. The data for each indicator are multipled by their loading and summed to generate the factor scores for the composite variable, which is then used in the structural model. Let’s demonstrate using some random data: set.seed(8) y &lt;- rnorm(50) x1 &lt;- rnorm(50) x2 &lt;- x1 + runif(50) # run multiple regression model &lt;- lm(y ~ x1 + x2) # get loadings beta_x1 &lt;- summary(model)$coefficients[2, 1] beta_x2 &lt;- summary(model)$coefficients[3, 1] # compute factor scores composite &lt;- beta_x1 * x1 + beta_x2 * x2 These values can then used to predict the response: summary(lm(y ~ composite)) ## ## Call: ## lm(formula = y ~ composite) ## ## Residuals: ## Min 1Q Median 3Q Max ## -2.88387 -0.70164 0.05644 0.54393 2.07769 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.3031 0.2424 -1.250 0.217 ## composite 1.0000 0.8045 1.243 0.220 ## ## Residual standard error: 1.014 on 48 degrees of freedom ## Multiple R-squared: 0.03118, Adjusted R-squared: 0.011 ## F-statistic: 1.545 on 1 and 48 DF, p-value: 0.2199 Note how the unstandardized coefficient is 1. This is because we the composite is essentially the predicted values of the response, so they are in the same units. Thus, the coefficient is really only interpretable in standardized units. Let’s alternately fit this composite model with lavaan and fix the loadings of \\(x1\\) and \\(x2\\) to the values from the multiple regression: library(lavaan) ## This is lavaan 0.6-2 ## lavaan is BETA software! Please report any bugs. comp_formula1 &lt;- &#39; composite &lt;~ -0.498 * x1 + 0.579 * x2 y ~ composite &#39; comp_model1 &lt;- sem(comp_formula1, data.frame(y, x1, x2)) summary(comp_model1, standardize = T) ## lavaan 0.6-2 ended normally after 14 iterations ## ## Optimization method NLMINB ## Number of free parameters 2 ## ## Number of observations 50 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 1 ## P-value (Chi-square) 0.999 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Composites: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## composite &lt;~ ## x1 -0.498 -2.793 -3.163 ## x2 0.579 3.248 3.642 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## y ~ ## composite 1.000 0.788 1.269 0.205 0.178 0.177 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .y 0.987 0.197 5.000 0.000 0.987 0.969 ## composite 0.000 0.000 0.000 We see from the output that the estimated loadings for our two indicators are the same values we provided, and consequently the understandardized coefficient is 1. However, the unstandardized coefficient is 0.177 and it is this value that we would present (although its non-significant, given that these are fake data). Let’s suppose we didn’t know the loadings from the multiple regression. We run into the same issue of identifiability as when constructing latent variables, so we must fix the first loading to 1. This will also define the scale of the copmosite. NOTE: lavaan does not do this automatically, we will have to implement it manually. comp_formula2 &lt;- &#39; composite &lt;~ 1 * x1 + x2 y ~ composite &#39; comp_model2 &lt;- sem(comp_formula2, data.frame(y, x1, x2)) ## Warning in lavaan::lavaan(model = comp_formula2, data = data.frame(y, x1, : ## lavaan WARNING: the optimizer warns that a solution has NOT been found! It seems that, because the true loading of \\(x1\\) on the composite is far from 1 (we know it is actually -0.498), we have received a non-convergence error! One solution is to set the other loading to 1: comp_formula3 &lt;- &#39; composite &lt;~ x1 + 1 * x2 y ~ composite &#39; comp_model3 &lt;- sem(comp_formula3, data.frame(y, x1, x2)) summary(comp_model3, standardize = T) ## lavaan 0.6-2 ended normally after 22 iterations ## ## Optimization method NLMINB ## Number of free parameters 3 ## ## Number of observations 50 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 0 ## Minimum Function Value 0.0000000000000 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Composites: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## composite &lt;~ ## x1 -0.860 0.230 -3.745 0.000 -2.792 -3.162 ## x2 1.000 3.247 3.642 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## y ~ ## composite 0.579 0.489 1.184 0.236 0.178 0.177 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .y 0.987 0.197 5.000 0.000 0.987 0.969 ## composite 0.000 0.000 0.000 Here the model converges because the true loading (0.579) is close enough to 1 for the maximum-likelihood fitting function to find it. Note that the unstandardized coefficient is no longer 1: this is because the scale of the composite has been set to that of the second indicator. However, the standardized coefficient is different from what we know the true relationship to be (0.236 vs. 0.177). For this reason, it is generally recommended that one compute the loadings by hand and fix them in the model. This has an added benefit we will get to in section 1.4. But first let’s explore a real-world example. 7.3 Grace &amp; Keeley Revisited: A Worked Example Recall from the chapter on “Global Estimation” that Grace &amp; Keeley (2006) were interested in the factors that mediated recovery of shrublands post-fire disturbance. In that chapter, we fit a sub-model of their larger model, and we’ll fit a different sub-model in this chapter. In their model, they used plant cover to predict plant species richness. Let’s assume for a moment that the relationship between cover and richness may be non-linear: its not until a certain amount of cover that rarer species begin to appear, for example. In this case, we might suppose there are both linear \\(cover\\) and non-linear \\(cover^2\\) components to the model. Composite variables are a nice way to summarize both the linear and non-linear effects. Let’s fit the following composite variable: keeley composite Here we have a composite that summarizes the unsquared and squared values of cover, which then goes on to predict richness. Let’s adopt the two-step approach and first fit a linear model. library(piecewiseSEM) ## ## This is piecewiseSEM version 2.1.0 ## ## ## If you have used the package before, it is strongly recommended you read Section 3 of the vignette(&#39;piecewiseSEM&#39;) to familiarize yourself with the new syntax ## ## Questions or bugs can be addressed to &lt;LefcheckJ@si.edu&gt; data(keeley) cover_model &lt;- lm(rich ~ cover + I(cover^2), keeley) summary(cover_model) ## ## Call: ## lm(formula = rich ~ cover + I(cover^2), data = keeley) ## ## Residuals: ## Min 1Q Median 3Q Max ## -29.161 -11.958 -0.595 10.094 32.956 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 25.641 6.574 3.900 0.000189 *** ## cover 57.999 18.931 3.064 0.002910 ** ## I(cover^2) -28.577 12.385 -2.307 0.023403 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 14 on 87 degrees of freedom ## Multiple R-squared: 0.1598, Adjusted R-squared: 0.1404 ## F-statistic: 8.271 on 2 and 87 DF, p-value: 0.0005147 It seems both the unsquared and squared values of cover significantly predict richness, so we are justified in including both as indicators to our composite variable. Now we extract the coefficients, use them to generate the factor scores, and finally use those scores to predict richness. beta_cover &lt;- summary(cover_model)$coefficients[2, 1] beta_cover2 &lt;- summary(cover_model)$coefficients[3, 1] composite &lt;- beta_cover * keeley$cover + beta_cover2 * (keeley$cover)^2 summary(lm(rich ~ composite, data = data.frame(keeley, composite))) ## ## Call: ## lm(formula = rich ~ composite, data = data.frame(keeley, composite)) ## ## Residuals: ## Min 1Q Median 3Q Max ## -29.161 -11.958 -0.595 10.094 32.956 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 25.6406 5.9516 4.308 4.27e-05 *** ## composite 1.0000 0.2445 4.090 9.51e-05 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 13.93 on 88 degrees of freedom ## Multiple R-squared: 0.1598, Adjusted R-squared: 0.1502 ## F-statistic: 16.73 on 1 and 88 DF, p-value: 9.507e-05 As would be expected from the multiple regression, the composite term significantly predicts richness (\\(P &lt; 0.001\\)). Let’s use the coefs function from piecewiseSEM to obtain the standardized coefficient: coefs(lm(rich ~ composite, data = data.frame(keeley, composite))) ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## 1 rich composite 1 0.2445 88 4.0904 1e-04 0.3997 ## ## 1 *** So a 1 SD change in the total cover effect would result in a 0.400 SD change in plant richness. We can alternately fit the model with lavaan using the same coefficients from the multiple regression: # create a new non-linear variable for cover^2 keeley$coversq &lt;- keeley$cover^2 keeley_formula1 &lt;- &#39; composite &lt;~ 58 * cover + -28.578 * coversq rich ~ composite &#39; keeley_model1 &lt;- sem(keeley_formula1, keeley, fixed.x = F) ## Warning in lav_data_full(data = data, group = group, cluster = cluster, : ## lavaan WARNING: some observed variances are (at least) a factor 1000 times ## larger than others; use varTable(fit) to investigate summary(keeley_model1, standardize = T) ## lavaan 0.6-2 ended normally after 20 iterations ## ## Optimization method NLMINB ## Number of free parameters 5 ## ## Number of observations 90 ## ## Estimator ML ## Model Fit Test Statistic 0.000 ## Degrees of freedom 1 ## P-value (Chi-square) 1.000 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Composites: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## composite &lt;~ ## cover 58.000 9.660 3.048 ## coversq -28.578 -4.760 -2.295 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## rich ~ ## composite 1.000 0.242 4.137 0.000 6.004 0.400 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## cover ~~ ## coversq 0.147 0.022 6.602 0.000 0.147 0.969 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .rich 189.597 28.263 6.708 0.000 189.597 0.840 ## composite 0.000 0.000 0.000 ## cover 0.100 0.015 6.708 0.000 0.100 1.000 ## coversq 0.233 0.035 6.708 0.000 0.233 1.000 We obtain the same standardized coefficient (0.400) as through the manual calculation. Finally, let’s incorporate the effect of fire severity on cover. Now the composite is endogenous because it is affected by fire severity, and goes on to predict richness. keeley endogenous composite First, we must fit the model without the composite to get the loadings of \\(cover\\) and \\(cover^2\\). Because the squared term is not a ‘true’ variable in the model but a convenience for us to explore this non-linearity, we must treat them as exogenous even though they are part of an endogenous composite. lavaan automatically models correlations among exogenous variables, but will not do so for the composite indicators. In this case, then, we must manually control for the correlation between \\(cover^2\\) and \\(cover\\) and \\(firesev\\). keeley_formula2 &lt;- &#39; composite &lt;~ 58 * cover + -28.578 * coversq rich ~ composite + firesev cover ~ firesev cover ~~ coversq firesev ~~ coversq &#39; keeley_model2 &lt;- sem(keeley_formula2, data.frame(keeley, composite)) ## Warning in lav_data_full(data = data, group = group, cluster = cluster, : ## lavaan WARNING: some observed variances are (at least) a factor 1000 times ## larger than others; use varTable(fit) to investigate summary(keeley_model2, standardize = T, rsq = T) ## lavaan 0.6-2 ended normally after 53 iterations ## ## Optimization method NLMINB ## Number of free parameters 9 ## ## Number of observations 90 ## ## Estimator ML ## Model Fit Test Statistic 0.065 ## Degrees of freedom 1 ## P-value (Chi-square) 0.799 ## ## Parameter Estimates: ## ## Information Expected ## Information saturated (h1) model Structured ## Standard Errors Standard ## ## Composites: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## composite &lt;~ ## cover 58.000 9.660 3.048 ## coversq -28.578 -4.760 -2.295 ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## rich ~ ## composite 0.731 0.265 2.757 0.006 4.391 0.292 ## firesev -2.132 0.969 -2.200 0.028 -2.132 -0.233 ## cover ~ ## firesev -0.084 0.018 -4.611 0.000 -0.084 -0.437 ## ## Covariances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .cover ~~ ## coversq 0.122 0.019 6.588 0.000 0.122 0.893 ## coversq ~~ ## firesev -0.301 0.089 -3.369 0.001 -0.301 -0.380 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) Std.lv Std.all ## .rich 179.922 26.821 6.708 0.000 179.922 0.797 ## .cover 0.081 0.012 6.708 0.000 0.081 0.809 ## coversq 0.233 0.035 6.708 0.000 0.233 1.000 ## firesev 2.700 0.402 6.708 0.000 2.700 1.000 ## composite 0.000 0.000 0.000 ## ## R-Square: ## Estimate ## rich 0.203 ## cover 0.191 Here, we find a good-fitting model (\\(P = 0.80\\)). Moreover, we obtain the standardized coefficient for the effect of fire severity on cover \\(\\gamma = -0.437\\) and of the composite on richness \\(\\beta = 0.292\\) controlling for fire severity, which is the total non-linear effect of cover. To otain the indirect effect then, we multiply these paths plus the standardized loading \\(cover\\) on the composite: \\(-0.437 * 3.048 * 0.292 = -0.389\\). 7.4 Composites in piecewiseSEM For the moment, composites are not directly implemented in piecewiseSEM but we hope to introduce that functionality shortly. In the interim, it is easy to compute them by hand, as we have shown above, extract the predicted scores, and use them as any other predictor: keeley$composite &lt;- composite keeley_psem &lt;- psem( lm(firesev ~ cover, keeley), lm(rich ~ composite + firesev, keeley) ) summary(keeley_psem) ## | | | 0% | |================================ | 50% | |=================================================================| 100% ## ## Structural Equation Model of keeley_psem ## ## Call: ## firesev ~ cover ## rich ~ composite + firesev ## ## AIC BIC ## 19.913 37.412 ## ## --- ## Tests of directed separation: ## ## Independ.Claim Estimate Std.Error DF Crit.Value P.Value ## rich ~ cover + ... -2.0305 8.1328 86 -0.2497 0.8034 ## firesev ~ composite + ... -0.0853 0.0456 87 -1.8710 0.0647 ## ## Global goodness-of-fit: ## ## Fisher&#39;s C = 5.913 with P-value = 0.206 and on 4 degrees of freedom ## ## --- ## Coefficients: ## ## Response Predictor Estimate Std.Error DF Crit.Value P.Value Std.Estimate ## firesev cover -2.2769 0.4994 88 -4.5594 0.0000 -0.4371 ## rich composite 0.7314 0.2698 87 2.7108 0.0081 0.2923 ## rich firesev -2.1323 0.9859 87 -2.1629 0.0333 -0.2332 ## ## *** ## ** ## * ## ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 ## ## Individual R-squared: ## ## Response method R.squared ## firesev none 0.19 ## rich none 0.20 7.5 References Grace, J. B., &amp; Keeley, J. E. (2006). A structural equation model analysis of postfire plant diversity in California shrublands. Ecological Applications, 16(2), 503-514. "]
]
